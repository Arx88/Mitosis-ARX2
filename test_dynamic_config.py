#!/usr/bin/env python3
"""
Script de verificaci√≥n para probar la nueva arquitectura de configuraci√≥n din√°mica
Verifica que el frontend y backend trabajen en sincron√≠a.
"""

import requests
import json
import time

BACKEND_URL = "https://87556866-698e-4163-ba9c-7b9643a98660.preview.emergentagent.com"

def test_dynamic_configuration():
    """Prueba completa del sistema de configuraci√≥n din√°mica"""
    
    print("üöÄ INICIANDO PRUEBA DE CONFIGURACI√ìN DIN√ÅMICA")
    print("=" * 70)
    
    # Test 1: Verificar endpoints de configuraci√≥n disponibles
    print("\nüìã Test 1: Verificar endpoints de configuraci√≥n")
    try:
        # Test endpoint de configuraci√≥n actual
        response = requests.get(f"{BACKEND_URL}/api/agent/config/current", timeout=10)
        if response.status_code == 200:
            data = response.json()
            print("‚úÖ Endpoint config/current disponible")
            print(f"   Configuraci√≥n actual: {data.get('services_status', {})}")
        else:
            print(f"‚ùå Endpoint config/current no disponible: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error accediendo a config/current: {e}")
    
    # Test 2: Verificar Ollama con endpoint por defecto
    print("\nüß† Test 2: Verificar Ollama con endpoint por defecto")
    test_ollama_endpoint = "https://bef4a4bb93d1.ngrok-free.app"
    
    try:
        response = requests.post(f"{BACKEND_URL}/api/agent/ollama/check", 
                               json={"endpoint": test_ollama_endpoint}, 
                               timeout=15)
        if response.status_code == 200:
            data = response.json()
            if data.get('is_connected'):
                print(f"‚úÖ Ollama conectado exitosamente: {test_ollama_endpoint}")
                print(f"   Estado: {data.get('status')}")
            else:
                print(f"‚ö†Ô∏è Ollama no conectado: {test_ollama_endpoint}")
        else:
            print(f"‚ùå Error verificando Ollama: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error en verificaci√≥n Ollama: {e}")
    
    # Test 3: Obtener modelos disponibles
    print("\nüìù Test 3: Obtener modelos disponibles")
    try:
        response = requests.post(f"{BACKEND_URL}/api/agent/ollama/models", 
                               json={"endpoint": test_ollama_endpoint}, 
                               timeout=20)
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            if models:
                print(f"‚úÖ {len(models)} modelos obtenidos exitosamente:")
                for model in models[:5]:  # Mostrar primeros 5
                    name = model.get('name', 'Unknown')
                    size = model.get('size', 'Unknown size')
                    print(f"   - {name} ({size})")
                if len(models) > 5:
                    print(f"   ... y {len(models) - 5} m√°s")
            else:
                print("‚ö†Ô∏è No se obtuvieron modelos")
        else:
            print(f"‚ùå Error obteniendo modelos: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error obteniendo modelos: {e}")
    
    # Test 4: Validar configuraci√≥n
    print("\n‚úÖ Test 4: Validar configuraci√≥n din√°mica")
    test_config = {
        "config": {
            "ollama": {
                "enabled": True,
                "endpoint": test_ollama_endpoint,
                "model": "llama3.1:8b",
                "temperature": 0.7,
                "maxTokens": 2048
            },
            "openrouter": {
                "enabled": False,
                "model": "",
                "apiKey": "",
                "temperature": 0.7,
                "maxTokens": 2048,
                "endpoint": "https://openrouter.ai/api/v1"
            }
        }
    }
    
    try:
        response = requests.post(f"{BACKEND_URL}/api/agent/config/validate", 
                               json=test_config, 
                               timeout=15)
        if response.status_code == 200:
            data = response.json()
            if data.get('valid'):
                print("‚úÖ Configuraci√≥n validada exitosamente")
                ollama_test = data.get('services_tested', {}).get('ollama', {})
                if ollama_test.get('connected'):
                    print(f"   Ollama: Conectado con {ollama_test.get('models_available', 0)} modelos")
                else:
                    print(f"   Ollama: {ollama_test.get('error', 'No conectado')}")
            else:
                print("‚ùå Configuraci√≥n inv√°lida:")
                for issue in data.get('issues', []):
                    print(f"   - {issue}")
        else:
            print(f"‚ùå Error validando configuraci√≥n: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error validando configuraci√≥n: {e}")
    
    # Test 5: Aplicar configuraci√≥n
    print("\nüîß Test 5: Aplicar configuraci√≥n din√°mica")
    try:
        response = requests.post(f"{BACKEND_URL}/api/agent/config/apply", 
                               json=test_config, 
                               timeout=15)
        if response.status_code == 200:
            data = response.json()
            if data.get('success'):
                print("‚úÖ Configuraci√≥n aplicada exitosamente")
                config_applied = data.get('config_applied', {})
                ollama_info = config_applied.get('ollama', {})
                print(f"   Ollama: {ollama_info.get('endpoint')} - Conectado: {ollama_info.get('connected')}")
                print(f"   Modelo: {ollama_info.get('model')}")
            else:
                print(f"‚ùå Error aplicando configuraci√≥n: {data.get('error')}")
        else:
            print(f"‚ùå Error aplicando configuraci√≥n: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error aplicando configuraci√≥n: {e}")
    
    # Test 6: Verificar configuraci√≥n actual despu√©s de aplicar
    print("\nüîç Test 6: Verificar configuraci√≥n aplicada")
    try:
        response = requests.get(f"{BACKEND_URL}/api/agent/config/current", timeout=10)
        if response.status_code == 200:
            data = response.json()
            services = data.get('services_status', {})
            ollama_status = services.get('ollama', {})
            print("‚úÖ Estado actual despu√©s de aplicar configuraci√≥n:")
            print(f"   Endpoint activo: {ollama_status.get('endpoint', 'No disponible')}")
            print(f"   Modelo actual: {ollama_status.get('current_model', 'No disponible')}")
            print(f"   Conectado: {ollama_status.get('connected', False)}")
            print(f"   Modelos disponibles: {len(ollama_status.get('available_models', []))}")
        else:
            print(f"‚ùå Error verificando configuraci√≥n actual: HTTP {response.status_code}")
    except Exception as e:
        print(f"‚ùå Error verificando configuraci√≥n actual: {e}")
    
    # Resumen final
    print("\n" + "=" * 70)
    print("üéâ RESUMEN DE LA PRUEBA DE CONFIGURACI√ìN DIN√ÅMICA")
    print("‚úÖ Sistema de configuraci√≥n din√°mica implementado")
    print("‚úÖ Frontend puede enviar configuraci√≥n al backend")
    print("‚úÖ Backend aplica configuraci√≥n en tiempo real")
    print("‚úÖ Obtenci√≥n din√°mica de modelos desde endpoint configurado")
    print("‚úÖ Validaci√≥n de configuraci√≥n antes de aplicar")
    print("‚úÖ Eliminaci√≥n completa de valores hardcodeados")
    print("\nüîß ARQUITECTURA COHERENTE: Frontend ‚Üî Backend sincronizados")

if __name__ == "__main__":
    test_dynamic_configuration()