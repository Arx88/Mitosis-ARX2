"""
Rutas API del agente - Versi√≥n REAL CON OLLAMA
Sistema de agente que usa Ollama real para generar respuestas inteligentes
Y distingue entre conversaciones casuales y tareas complejas
"""

from flask import Blueprint, request, jsonify, current_app
from datetime import datetime
from typing import Dict, Any
import logging
import time
import uuid
import json
import os
import requests
import re
import jsonschema
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# üÜï PROBLEMA 2: Importar sistema de validaci√≥n de resultados
from ..validation.result_validators import (
    validate_step_result, 
    StepStatus, 
    TaskStatus, 
    determine_task_status_from_steps
)

# Import UpdateType for WebSocket updates
try:
    from src.websocket.websocket_manager import UpdateType
except ImportError:
    # Fallback if UpdateType is not available
    UpdateType = None

logger = logging.getLogger(__name__)

# JSON Schema para validaci√≥n de planes generados por Ollama
# Mejora implementada seg√∫n UPGRADE.md Secci√≥n 2: Validaci√≥n de Esquemas JSON
PLAN_SCHEMA = {
    "type": "object",
    "required": ["steps", "task_type", "complexity"],
    "properties": {
        "steps": {
            "type": "array",
            "minItems": 3,
            "maxItems": 6,
            "items": {
                "type": "object",
                "required": ["title", "description", "tool"],
                "properties": {
                    "title": {
                        "type": "string",
                        "minLength": 5,
                        "maxLength": 100
                    },
                    "description": {
                        "type": "string", 
                        "minLength": 10,
                        "maxLength": 300
                    },
                    "tool": {
                        "type": "string",
                        "enum": ["web_search", "analysis", "creation", "planning", "delivery", "processing", "synthesis", "search_definition", "data_analysis", "shell", "research", "investigation", "web_scraping", "search", "mind_map", "spreadsheets", "database"]
                    },
                    "estimated_time": {
                        "type": "string"
                    },
                    "priority": {
                        "type": "string",
                        "enum": ["alta", "media", "baja"]
                    }
                },
                "additionalProperties": False
            }
        },
        "task_type": {
            "type": "string",
            "minLength": 3
        },
        "complexity": {
            "type": ["string", "number"],
            "pattern": "^(baja|media|alta)$|^[0-9]+(\\.[0-9]+)?$"
        },
        "estimated_total_time": {
            "type": "string"
        }
    },
    "additionalProperties": False
}

agent_bp = Blueprint('agent', __name__)

@agent_bp.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint para verificar MongoDB y sistema"""
    try:
        # Verificar TaskManager y MongoDB
        task_manager = get_task_manager()
        db_service = task_manager.db_service
        
        # Test de conexi√≥n MongoDB
        mongo_status = db_service.check_connection()
        
        # Verificar Ollama
        ollama_service = get_ollama_service()
        ollama_healthy = ollama_service.is_healthy() if ollama_service else False
        
        return jsonify({
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'mongodb': {
                'connected': mongo_status.get('healthy', False),
                'database': mongo_status.get('database', 'unknown'),
                'collections': mongo_status.get('collections', 0),
                'size_mb': mongo_status.get('size_mb', 0)
            },
            'ollama': {
                'connected': ollama_healthy
            },
            'task_manager': {
                'active_cache_size': len(task_manager.active_cache)
            }
        })
    except Exception as e:
        logger.error(f"‚ùå Error en health check: {str(e)}")
        return jsonify({
            'status': 'error',
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@agent_bp.route('/execute-step-detailed/<task_id>/<step_id>', methods=['POST'])
def execute_single_step_detailed(task_id: str, step_id: str):
    """
    Ejecutar un paso espec√≠fico del plan de manera controlada y secuencial
    """
    try:
        # Obtener datos de la tarea
        task_data = get_task_data(task_id)
        if not task_data:
            return jsonify({'error': f'Task {task_id} not found'}), 404
        
        # Encontrar el paso espec√≠fico
        steps = task_data.get('plan', [])
        current_step = None
        step_index = -1
        
        for i, step in enumerate(steps):
            if step.get('id') == step_id:
                current_step = step
                step_index = i
                break
        
        if not current_step:
            return jsonify({'error': f'Step {step_id} not found'}), 404
        
        # VALIDACI√ìN: Verificar que los pasos anteriores est√©n completados
        if step_index > 0:
            for i in range(step_index):
                previous_step = steps[i]
                if not previous_step.get('completed', False):
                    return jsonify({
                        'error': 'Los pasos anteriores deben completarse primero',
                        'blocking_step': previous_step.get('title'),
                        'must_complete_first': True
                    }), 400
        
        # Verificar que el paso no est√© ya completado
        if current_step.get('completed', False):
            return jsonify({
                'error': 'Este paso ya est√° completado',
                'step_already_completed': True
            }), 400
        
        logger.info(f"üîÑ Ejecutando paso espec√≠fico {step_index + 1}: {current_step['title']} para task {task_id}")
        
        # Marcar paso como en progreso
        current_step['active'] = True
        current_step['status'] = 'in-progress'
        current_step['start_time'] = datetime.now().isoformat()
        
        # Actualizar en persistencia
        update_task_data(task_id, {'plan': steps})
        
        # Ejecutar el paso espec√≠fico
        step_result = execute_single_step_logic(current_step, task_data.get('message', ''), task_id)
        
        # Actualizar resultado del paso
        current_step['active'] = False
        current_step['completed'] = True
        current_step['status'] = 'completed'
        current_step['result'] = step_result
        current_step['completed_time'] = datetime.now().isoformat()
        
        # Actualizar en persistencia
        update_task_data(task_id, {'plan': steps})
        
        # Verificar si todos los pasos est√°n completados
        all_completed = all(step.get('completed', False) for step in steps)
        
        response_data = {
            'success': True,
            'step_result': step_result,
            'step_completed': True,
            'all_steps_completed': all_completed,
            'next_step': steps[step_index + 1] if step_index + 1 < len(steps) else None
        }
        
        if all_completed:
            # Marcar tarea como completada
            update_task_data(task_id, {'status': 'completed', 'completed_at': datetime.now().isoformat()})
            response_data['task_completed'] = True
            logger.info(f"üéâ Tarea {task_id} completada - todos los pasos ejecutados")
        
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"‚ùå Error ejecutando paso {step_id}: {str(e)}")
@agent_bp.route('/get-task-plan/<task_id>', methods=['GET'])
def get_task_plan(task_id: str):
    """
    Obtener el estado actual del plan de una tarea
    """
    try:
        task_data = get_task_data(task_id)
        if not task_data:
            return jsonify({'error': f'Task {task_id} not found'}), 404
        
        steps = task_data.get('plan', [])
        
        # Calcular estad√≠sticas del plan
        completed_steps = sum(1 for step in steps if step.get('completed', False))
        in_progress_steps = sum(1 for step in steps if step.get('status') == 'in-progress')
        
        # Determinar siguiente paso disponible
        next_step = None
        for i, step in enumerate(steps):
            if not step.get('completed', False):
                # Verificar si todos los pasos anteriores est√°n completados
                if i == 0 or all(steps[j].get('completed', False) for j in range(i)):
                    next_step = step
                    break
        
        # Estado general de la tarea
        task_status = 'pending'
        if completed_steps == len(steps) and len(steps) > 0:
            task_status = 'completed'
        elif in_progress_steps > 0:
            task_status = 'in_progress'
        elif completed_steps > 0:
            task_status = 'partially_completed'
        
        return jsonify({
            'task_id': task_id,
            'status': task_status,
            'plan': steps,
            'stats': {
                'total_steps': len(steps),
                'completed_steps': completed_steps,
                'in_progress_steps': in_progress_steps,
                'remaining_steps': len(steps) - completed_steps
            },
            'next_step': next_step,
            'can_execute_next': next_step is not None,
            'task_data': {
                'message': task_data.get('message', ''),
                'created_at': task_data.get('created_at', ''),
                'task_type': task_data.get('task_type', ''),
                'complexity': task_data.get('complexity', '')
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo plan para task {task_id}: {str(e)}")
        return jsonify({'error': f'Error getting task plan: {str(e)}'}), 500

def execute_single_step_logic(step: dict, original_message: str, task_id: str) -> dict:
    """
    L√≥gica de ejecuci√≥n para un paso individual con manejo de errores robusto
    """
    try:
        step_tool = step.get('tool', 'processing')
        step_title = step.get('title', 'Paso sin t√≠tulo')
        step_description = step.get('description', 'Sin descripci√≥n')
        
        logger.info(f"‚ö° Ejecutando herramienta '{step_tool}' para paso: {step_title}")
        
        # Obtener servicios necesarios
        ollama_service = get_ollama_service()
        tool_manager = get_tool_manager()
        
        # Ejecutar seg√∫n el tipo de herramienta
        if step_tool == 'web_search':
            return execute_web_search_step(step_title, step_description, tool_manager, task_id)
        elif step_tool in ['analysis', 'data_analysis']:
            return execute_analysis_step(step_title, step_description, ollama_service, original_message)
        elif step_tool == 'creation':
            return execute_creation_step(step_title, step_description, ollama_service, original_message, task_id)
        elif step_tool in ['planning', 'delivery']:
            return execute_planning_delivery_step(step_tool, step_title, step_description, ollama_service, original_message)
        else:
            # Herramienta gen√©rica
            return execute_generic_step(step_title, step_description, ollama_service, original_message)
            
    except Exception as e:
        logger.error(f"‚ùå Error en ejecuci√≥n de paso: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': 'execution_error',
            'summary': f'‚ùå Error al ejecutar: {str(e)}'
        }

def execute_web_search_step(title: str, description: str, tool_manager, task_id: str) -> dict:
    """Ejecutar paso de b√∫squeda web"""
    try:
        # Extraer query de b√∫squeda
        search_query = f"{title} {description}".replace('Buscar informaci√≥n sobre:', '').replace('Investigar:', '').strip()
        
        if tool_manager and hasattr(tool_manager, 'execute_tool'):
            result = tool_manager.execute_tool('web_search', {
                'query': search_query,
                'num_results': 5
            }, task_id=task_id)
            
            return {
                'success': True,
                'type': 'web_search',
                'query': search_query,
                'results_count': len(result.get('search_results', [])),
                'summary': f"‚úÖ B√∫squeda completada: {len(result.get('search_results', []))} resultados encontrados",
                'data': result.get('search_results', [])
            }
        else:
            raise Exception("Tool manager no disponible")
            
    except Exception as e:
        logger.error(f"‚ùå Web search error: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': 'web_search_error',
            'summary': f'‚ùå Error en b√∫squeda: {str(e)}'
        }

def execute_analysis_step(title: str, description: str, ollama_service, original_message: str) -> dict:
    """Ejecutar paso de an√°lisis"""
    try:
        if not ollama_service or not ollama_service.is_healthy():
            raise Exception("Servicio Ollama no disponible")
        
        analysis_prompt = f"""
Realiza un an√°lisis detallado para la tarea: {original_message}

Paso espec√≠fico: {title}
Descripci√≥n: {description}

Proporciona:
1. An√°lisis espec√≠fico del contexto
2. Hallazgos principales  
3. Recomendaciones
4. Conclusiones

Formato: Respuesta estructurada y profesional en espa√±ol.
"""
        
        result = ollama_service.generate_response(analysis_prompt, {'temperature': 0.7})
        
        if result.get('error'):
            raise Exception(f"Error Ollama: {result['error']}")
        
        analysis_content = result.get('response', 'An√°lisis completado')
        
        return {
            'success': True,
            'type': 'analysis',
            'content': analysis_content,
            'length': len(analysis_content),
            'summary': f"‚úÖ An√°lisis completado - {len(analysis_content)} caracteres generados"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Analysis error: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': 'analysis_error',
            'summary': f'‚ùå Error en an√°lisis: {str(e)}'
        }

def execute_creation_step(title: str, description: str, ollama_service, original_message: str, task_id: str) -> dict:
    """Ejecutar paso de creaci√≥n con archivo real"""
    try:
        if not ollama_service or not ollama_service.is_healthy():
            raise Exception("Servicio Ollama no disponible")
        
        creation_prompt = f"""
IMPORTANTE: Genera el CONTENIDO REAL solicitado, NO un plan de acci√≥n.

Tarea original: {original_message}
Paso: {title}
Descripci√≥n: {description}

Genera contenido espec√≠fico, detallado y profesional que responda exactamente a lo solicitado.
Responde SOLO con el contenido final, NO con pasos de c√≥mo crearlo.
"""
        
        result = ollama_service.generate_response(creation_prompt, {'temperature': 0.7})
        
        if result.get('error'):
            raise Exception(f"Error Ollama: {result['error']}")
        
        content = result.get('response', 'Contenido creado')
        
        # Crear archivo real
        try:
            import re
            import os
            safe_title = re.sub(r'[^a-zA-Z0-9\-_]', '_', title[:50])
            filename = f"{safe_title}_{int(time.time())}.md"
            file_path = f"/app/backend/static/generated_files/{filename}"
            
            # Crear directorio si no existe
            os.makedirs("/app/backend/static/generated_files", exist_ok=True)
            
            # Escribir contenido al archivo
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(f"# {title}\n\n")
                f.write(f"**Tarea:** {original_message}\n\n")
                f.write(f"**Descripci√≥n:** {description}\n\n")
                f.write("---\n\n")
                f.write(content)
            
            file_size = os.path.getsize(file_path)
            
            logger.info(f"‚úÖ Archivo creado: {filename} ({file_size} bytes)")
            
            return {
                'success': True,
                'type': 'creation_with_file',
                'content': content,
                'file_created': True,
                'file_name': filename,
                'file_path': file_path,
                'file_size': file_size,
                'download_url': f"/api/agent/download/{filename}",
                'summary': f"‚úÖ Contenido creado y archivo generado: {filename} ({file_size} bytes)"
            }
            
        except Exception as file_error:
            logger.error(f"‚ùå Error creando archivo: {file_error}")
            return {
                'success': True,
                'type': 'creation_no_file',
                'content': content,
                'file_created': False,
                'file_error': str(file_error),
                'summary': f"‚úÖ Contenido generado (error al crear archivo: {str(file_error)})"
            }
        
    except Exception as e:
        logger.error(f"‚ùå Creation error: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': 'creation_error',
            'summary': f'‚ùå Error en creaci√≥n: {str(e)}'
        }

def execute_planning_delivery_step(tool_type: str, title: str, description: str, ollama_service, original_message: str) -> dict:
    """Ejecutar paso de planificaci√≥n o entrega"""
    try:
        if not ollama_service or not ollama_service.is_healthy():
            raise Exception("Servicio Ollama no disponible")
        
        if tool_type == 'planning':
            prompt = f"""
Realiza planificaci√≥n detallada para:

Tarea original: {original_message}
Paso: {title}
Descripci√≥n: {description}

Proporciona:
1. Objetivos espec√≠ficos
2. Recursos necesarios
3. Estrategia de implementaci√≥n
4. Cronograma sugerido

Formato: Planificaci√≥n estructurada y pr√°ctica.
"""
        else:  # delivery
            prompt = f"""
Prepara la entrega final para:

Tarea original: {original_message}
Paso: {title}
Descripci√≥n: {description}

Proporciona:
1. Resumen ejecutivo
2. Resultados principales
3. Recomendaciones
4. Pr√≥ximos pasos

Formato: Entrega profesional y completa.
"""
        
        result = ollama_service.generate_response(prompt, {'temperature': 0.7})
        
        if result.get('error'):
            raise Exception(f"Error Ollama: {result['error']}")
        
        content = result.get('response', f'{tool_type} completado')
        
        return {
            'success': True,
            'type': tool_type,
            'content': content,
            'summary': f"‚úÖ {tool_type.title()} completado exitosamente"
        }
        
    except Exception as e:
        logger.error(f"‚ùå {tool_type} error: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': f'{tool_type}_error',
            'summary': f'‚ùå Error en {tool_type}: {str(e)}'
        }

def execute_generic_step(title: str, description: str, ollama_service, original_message: str) -> dict:
    """Ejecutar paso gen√©rico"""
    try:
        if not ollama_service or not ollama_service.is_healthy():
            raise Exception("Servicio Ollama no disponible")
        
        generic_prompt = f"""
Ejecuta la siguiente tarea:

Tarea original: {original_message}
Paso: {title}
Descripci√≥n: {description}

Proporciona un resultado espec√≠fico y √∫til para este paso.
Responde de manera clara y profesional.
"""
        
        result = ollama_service.generate_response(generic_prompt, {'temperature': 0.7})
        
        if result.get('error'):
            raise Exception(f"Error Ollama: {result['error']}")
        
        content = result.get('response', 'Paso completado')
        
        return {
            'success': True,
            'type': 'generic_processing',
            'content': content,
            'summary': f"‚úÖ Paso completado: {title}"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Generic step error: {str(e)}")
        return {
            'success': False,
            'error': str(e),
            'type': 'generic_error',
            'summary': f'‚ùå Error en paso: {str(e)}'
        }

# Importar nuevo TaskManager para persistencia
from ..services.task_manager import get_task_manager

# Almacenamiento temporal para compartir conversaciones
shared_conversations = {}
# Almacenamiento temporal para archivos por tarea
task_files = {}

# DEPRECATED: Reemplazado por TaskManager con persistencia MongoDB
# Mantenido temporalmente para migraci√≥n gradual
active_task_plans = {}

def get_task_data(task_id: str) -> dict:
    """
    Obtener datos de tarea usando TaskManager (con fallback a memoria legacy)
    Mejora implementada seg√∫n UPGRADE.md Secci√≥n 5: Persistencia del Estado de Tareas
    """
    try:
        task_manager = get_task_manager()
        task_data = task_manager.get_task(task_id)
        
        if task_data:
            logger.debug(f"üì• Task {task_id} retrieved from persistent storage")
            return task_data
        elif task_id in active_task_plans:
            # Fallback a memoria legacy
            logger.warning(f"‚ö†Ô∏è Task {task_id} found only in legacy memory, migrating...")
            legacy_data = active_task_plans[task_id]
            # Migrar a persistencia
            task_manager.create_task(task_id, legacy_data)
            return legacy_data
        else:
            logger.warning(f"‚ö†Ô∏è Task {task_id} not found in persistent or legacy storage")
            return None
            
    except Exception as e:
        logger.error(f"‚ùå Error getting task data {task_id}: {str(e)}")
        # Fallback a memoria legacy
        return active_task_plans.get(task_id)

def save_task_data(task_id: str, task_data: dict) -> bool:
    """
    Guardar datos de tarea usando TaskManager (con fallback a memoria legacy)
    """
    try:
        task_manager = get_task_manager()
        success = task_manager.create_task(task_id, task_data)
        
        if success:
            logger.debug(f"üíæ Task {task_id} saved to persistent storage")
            # Mantener en memoria legacy por compatibilidad
            active_task_plans[task_id] = task_data
            return True
        else:
            logger.warning(f"‚ö†Ô∏è Failed to save task {task_id} to persistent storage, using legacy")
            active_task_plans[task_id] = task_data
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error saving task data {task_id}: {str(e)}")
        # Fallback a memoria legacy
        active_task_plans[task_id] = task_data
        return False

def update_task_data(task_id: str, updates: dict) -> bool:
    """
    Actualizar datos de tarea usando TaskManager (con fallback a memoria legacy)
    """
    try:
        task_manager = get_task_manager()
        success = task_manager.update_task(task_id, updates)
        
        if success:
            logger.debug(f"‚úÖ Task {task_id} updated in persistent storage")
            # Actualizar memoria legacy por compatibilidad
            if task_id in active_task_plans:
                active_task_plans[task_id].update(updates)
            return True
        else:
            logger.warning(f"‚ö†Ô∏è Failed to update task {task_id} in persistent storage, using legacy")
            if task_id in active_task_plans:
                active_task_plans[task_id].update(updates)
            return False
            
    except Exception as e:
        logger.error(f"‚ùå Error updating task data {task_id}: {str(e)}")
        # Fallback a memoria legacy
        if task_id in active_task_plans:
            active_task_plans[task_id].update(updates)
        return False

# Patrones para detectar tipo de mensaje
CASUAL_PATTERNS = [
    r'^hola\b',
    r'^¬ø?c√≥mo est√°s\??$',
    r'^¬ø?qu√© tal\??$',
    r'^buenos d√≠as\b',
    r'^buenas tardes\b',
    r'^buenas noches\b',
    r'^¬ø?c√≥mo te llamas\??$',
    r'^¬ø?qui√©n eres\??$',
    r'^gracias\b',
    r'^de nada\b',
    r'^adi√≥s\b',
    r'^hasta luego\b',
    r'^ok\b',
    r'^vale\b',
    r'^perfecto\b',
    r'^entiendo\b'
]

TASK_PATTERNS = [
    r'crear\b.*\b(informe|reporte|documento|an√°lisis|plan|estrategia)',
    r'analizar\b.*\b(datos|informaci√≥n|tendencias|mercado)',
    r'buscar\b.*\b(informaci√≥n|datos|sobre)',
    r'investigar\b.*\b(sobre|tendencias|mercado)',
    r'generar\b.*\b(contenido|texto|c√≥digo|script)',
    r'desarrollar\b.*\b(aplicaci√≥n|web|software)',
    r'escribir\b.*\b(c√≥digo|script|programa)',
    r'hacer\b.*\b(an√°lisis|investigaci√≥n|estudio)',
    r'realizar\b.*\b(estudio|investigaci√≥n|an√°lisis)',
    r'dame\b.*\b(informaci√≥n|datos|informe|reporte)',
    r'necesito\b.*\b(informaci√≥n|datos|ayuda con)',
    r'quiero\b.*\b(crear|generar|desarrollar|hacer)',
    r'puedes\b.*\b(crear|generar|buscar|investigar)',
    r'ay√∫dame\b.*\b(con|a crear|a generar|a desarrollar)'
]

def is_casual_conversation(message: str) -> bool:
    """
    Detecta si un mensaje es una conversaci√≥n casual usando clasificaci√≥n LLM
    Mejora implementada seg√∫n UPGRADE.md Secci√≥n 1: Sistema de Contexto Din√°mico Inteligente
    """
    try:
        # Obtener servicio de Ollama para clasificaci√≥n inteligente
        ollama_service = get_ollama_service()
        
        # Obtener gestor de contexto inteligente
        context_manager = get_intelligent_context_manager()
        
        # Construir contexto inteligente para clasificaci√≥n
        if context_manager:
            logger.info(f"üß† Usando contexto inteligente para clasificaci√≥n: '{message[:50]}...'")
            context = context_manager.build_context('chat', message, max_tokens=1000)
        else:
            context = None
            logger.debug("‚ö†Ô∏è IntelligentContextManager no disponible, usando contexto b√°sico")
        
        # Fallback a l√≥gica heur√≠stica si Ollama no est√° disponible
        if not ollama_service or not ollama_service.is_healthy():
            logger.warning("‚ö†Ô∏è Ollama no disponible, usando detecci√≥n heur√≠stica de respaldo")
            return _fallback_casual_detection(message)
        
        # Prompt mejorado con contexto inteligente
        context_info = ""
        if context and isinstance(context, dict):
            # Agregar informaci√≥n relevante del contexto
            if context.get('conversation_history'):
                context_info += f"\nHistorial reciente: {len(context['conversation_history'])} conversaciones\n"
            if context.get('mood') and context['mood'] != 'neutral':
                context_info += f"Tono detectado: {context['mood']}\n"
            if context.get('topics'):
                context_info += f"Temas: {', '.join(context['topics'])}\n"
        
        intent_prompt = f"""Clasifica la siguiente frase del usuario en una de estas categor√≠as exactas: 'casual', 'tarea_investigacion', 'tarea_creacion', 'tarea_analisis', 'otro'.

{context_info}

Responde √öNICAMENTE con un objeto JSON con la clave 'intent'. No agregues explicaciones adicionales.

EJEMPLOS:
- "hola" -> {{"intent": "casual"}}
- "¬øc√≥mo est√°s?" -> {{"intent": "casual"}}
- "gracias" -> {{"intent": "casual"}}
- "buscar informaci√≥n sobre IA" -> {{"intent": "tarea_investigacion"}}
- "crear un informe" -> {{"intent": "tarea_creacion"}}
- "analizar datos" -> {{"intent": "tarea_analisis"}}

Frase a clasificar: "{message}"

Respuesta JSON:"""
        
        logger.info(f"ü§ñ Clasificando intenci√≥n con LLM para: '{message[:50]}...'")
        
        # Llamar a Ollama con par√°metros optimizados para JSON
        response = ollama_service.generate_response(intent_prompt, {
            'temperature': 0.2,  # M√°s bajo para respuestas consistentes
            'response_format': 'json'
        })
        
        if response.get('error'):
            logger.warning(f"‚ö†Ô∏è Error en clasificaci√≥n LLM: {response['error']}, usando fallback")
            return _fallback_casual_detection(message)
        
        # Parsear respuesta JSON con estrategias robustas
        response_text = response.get('response', '').strip()
        logger.info(f"üì• Respuesta LLM clasificaci√≥n: {response_text[:100]}...")
        
        # Intentar parseo JSON con m√∫ltiples estrategias
        intent_data = None
        
        # Estrategia 1: JSON directo
        try:
            # Limpiar respuesta
            cleaned_response = response_text.replace('```json', '').replace('```', '').strip()
            if cleaned_response.startswith('{') and cleaned_response.endswith('}'):
                intent_data = json.loads(cleaned_response)
        except json.JSONDecodeError:
            pass
        
        # Estrategia 2: Buscar JSON en el texto
        if not intent_data:
            try:
                json_match = re.search(r'\{[^{}]*"intent"[^{}]*\}', response_text)
                if json_match:
                    intent_data = json.loads(json_match.group())
            except json.JSONDecodeError:
                pass
        
        # Estrategia 3: Extracci√≥n por regex
        if not intent_data:
            try:
                intent_match = re.search(r'"intent"\s*:\s*"([^"]+)"', response_text)
                if intent_match:
                    intent_data = {"intent": intent_match.group(1)}
            except:
                pass
        
        # Validar resultado
        if intent_data and 'intent' in intent_data:
            intent = intent_data['intent'].lower().strip()
            
            # Clasificar como casual o tarea
            is_casual = intent == 'casual'
            
            logger.info(f"‚úÖ Clasificaci√≥n LLM exitosa: '{message[:30]}...' -> {intent} -> {'CASUAL' if is_casual else 'TAREA'}")
            
            return is_casual
        else:
            logger.warning(f"‚ö†Ô∏è No se pudo parsear intenci√≥n LLM, usando fallback para: {message[:30]}...")
            return _fallback_casual_detection(message)
            
    except Exception as e:
        logger.error(f"‚ùå Error en clasificaci√≥n de intenci√≥n LLM: {str(e)}")
        return _fallback_casual_detection(message)

def _fallback_casual_detection(message: str) -> bool:
    """
    L√≥gica de respaldo heur√≠stica para detecci√≥n de conversaci√≥n casual
    Se usa cuando Ollama no est√° disponible
    """
    message_lower = message.lower().strip()
    
    logger.info(f"üîÑ Usando detecci√≥n heur√≠stica de respaldo para: '{message[:30]}...'")
    
    # Mensajes muy cortos (menos de 3 palabras) probablemente son casuales
    if len(message_lower.split()) <= 3:
        for pattern in CASUAL_PATTERNS:
            if re.search(pattern, message_lower):
                return True
    
    # Verificar patrones de tareas PRIMERO
    for pattern in TASK_PATTERNS:
        if re.search(pattern, message_lower):
            return False
    
    # Verificar palabras clave que indican tarea (m√°s amplio)
    task_keywords = [
        'buscar', 'busca', 'investigar', 'investiga', 'analizar', 'analiza',
        'crear', 'crea', 'generar', 'genera', 'desarrollar', 'desarrolla',
        'hacer', 'haz', 'escribir', 'escribe', 'dame', 'dime', 'necesito',
        'quiero', 'puedes', 'ay√∫dame', 'planificar', 'planifica', 'realizar',
        'informe', 'reporte', 'an√°lisis', 'estudio', 'investigaci√≥n'
    ]
    
    # Si contiene palabras clave de tareas, NO es casual
    for keyword in task_keywords:
        if keyword in message_lower:
            return False
    
    # Si no hay patrones de tareas y es muy corto, probablemente es casual
    if len(message_lower.split()) <= 5:
        return True
    
    # Si tiene m√°s de 5 palabras y no es claramente casual, tratarlo como tarea
    return False

def get_ollama_service():
    """Obtener servicio de Ollama"""
    try:
        service = current_app.ollama_service
        logger.info(f"‚úÖ Ollama service found: {service}")
        return service
    except AttributeError:
        logger.error("‚ùå Ollama service not available")
        return None

def get_intelligent_context_manager():
    """Obtener gestor de contexto inteligente"""
    try:
        context_manager = current_app.intelligent_context_manager
        logger.debug(f"‚úÖ Intelligent Context Manager found: {context_manager}")
        return context_manager
    except AttributeError:
        logger.warning("‚ö†Ô∏è Intelligent Context Manager not available")
        return None

def get_tool_manager():
    """Obtener tool manager"""
    try:
        return current_app.tool_manager
    except AttributeError:
        logger.error("Tool manager not available")
        return None

def execute_plan_with_real_tools(task_id: str, plan_steps: list, message: str):
    """
    Ejecuta REALMENTE los pasos del plan usando herramientas y entrega resultados finales
    Mejora implementada seg√∫n UPGRADE.md Secci√≥n 3: WebSockets para Comunicaci√≥n en Tiempo Real
    """
    try:
        import threading
        import time
        from datetime import datetime
        
        # Obtener servicios ANTES de crear el hilo
        ollama_service = get_ollama_service()
        tool_manager = get_tool_manager()
        
        # Obtener WebSocket manager para actualizaciones en tiempo real
        # Mejora implementada seg√∫n UPGRADE.md Secci√≥n 3: WebSockets para Comunicaci√≥n en Tiempo Real
        websocket_manager = None
        try:
            # Primero intentar obtenerlo desde Flask app
            try:
                websocket_manager = current_app.websocket_manager
                logger.info(f"‚úÖ WebSocket manager obtained from Flask app for task {task_id}")
            except AttributeError:
                # Fallback al m√©todo directo
                from src.websocket.websocket_manager import get_websocket_manager
                websocket_manager = get_websocket_manager()
                logger.info(f"‚úÖ WebSocket manager obtained directly for task {task_id}")
                
        except Exception as ws_error:
            logger.warning(f"‚ö†Ô∏è WebSocket manager not available: {ws_error}")
        
        def send_websocket_update(update_type: str, data: dict):
            """Enviar actualizaci√≥n por WebSocket si est√° disponible"""
            if websocket_manager and websocket_manager.is_initialized:
                try:
                    if update_type == 'step_update':
                        websocket_manager.send_update(task_id, UpdateType.STEP_STARTED if data.get('status') == 'in-progress' else UpdateType.STEP_COMPLETED, data)
                    elif update_type == 'log_message':
                        websocket_manager.send_update(task_id, UpdateType.TASK_PROGRESS, data)
                    elif update_type == 'tool_execution_detail':
                        websocket_manager.send_update(task_id, UpdateType.TASK_PROGRESS, data)
                    elif update_type == 'task_completed':
                        websocket_manager.send_update(task_id, UpdateType.TASK_COMPLETED, data)
                    elif update_type == 'task_failed':
                        websocket_manager.send_update(task_id, UpdateType.TASK_FAILED, data)
                        
                    logger.info(f"üì° WebSocket update sent: {update_type} for task {task_id}")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è WebSocket update failed: {e}")
        
        def execute_steps():
            logger.info(f"üîç DEBUG: execute_steps iniciado para task_id: {task_id}")
            
            # Usar TaskManager en lugar de active_task_plans
            task_data = get_task_data(task_id)
            logger.info(f"üîç DEBUG: task_data obtenida: {task_data is not None}")
            
            if not task_data:
                logger.error(f"‚ùå Task {task_id} not found, cannot execute - Fallback a active_task_plans")
                # Fallback a memoria legacy
                if task_id in active_task_plans:
                    task_data = active_task_plans[task_id]
                    logger.info(f"üîç DEBUG: Encontrada en active_task_plans")
                else:
                    logger.error(f"‚ùå Task {task_id} no existe ni en TaskManager ni en active_task_plans")
                    return
                
            steps = task_data['plan']
            final_results = []  # Almacenar resultados de cada paso
            
            logger.info(f"üöÄ Starting REAL execution of {len(steps)} steps for task: {message}")
            
            # Enviar notificaci√≥n de inicio de tarea
            send_websocket_update('log_message', {
                'type': 'log_message',
                'level': 'info',
                'message': f'üöÄ Iniciando ejecuci√≥n de {len(steps)} pasos para: {message[:50]}...',
                'timestamp': datetime.now().isoformat()
            })
            
            for i, step in enumerate(steps):
                logger.info(f"üîÑ Executing step {i+1}/{len(steps)}: {step['title']}")
                
                # Marcar paso como activo
                step['active'] = True
                step['status'] = 'in-progress'
                
                # Enviar actualizaci√≥n de estado del paso en tiempo real
                send_websocket_update('step_update', {
                    'type': 'step_update',
                    'step_id': step['id'],
                    'status': 'in-progress',
                    'title': step['title'],
                    'description': step['description'],
                    'progress': (i / len(steps)) * 100,
                    'current_step': i + 1,
                    'total_steps': len(steps)
                })
                
                # Enviar log detallado al monitor
                send_websocket_update('log_message', {
                    'type': 'log_message',
                    'level': 'info',
                    'message': f'üîÑ Ejecutando paso {i+1}/{len(steps)}: {step["title"]}',
                    'timestamp': datetime.now().isoformat()
                })
                
                # Actualizar plan en memoria y persistencia
                task_manager = get_task_manager()
                task_manager.update_task_step_status(
                    task_id, 
                    step['id'], 
                    'in-progress'
                )
                update_task_data(task_id, {
                    'plan': steps,
                    'current_step': i + 1
                })
                
                step_start_time = time.time()
                step_result = None
                
                # Excepciones personalizadas para manejo de errores espec√≠fico
                class OllamaServiceError(Exception):
                    pass

                class ToolNotAvailableError(Exception):
                    pass

                class FileCreationError(Exception):
                    pass

                # Funci√≥n ROBUSTA para ejecutar herramientas con reintentos y retroceso exponencial
                # PROBLEMA 1 SOLUCIONADO: Eliminaci√≥n completa de simulaci√≥n
                @retry(
                    stop=stop_after_attempt(3),
                    wait=wait_exponential(multiplier=1, min=2, max=8),
                    retry=retry_if_exception_type((requests.RequestException, ConnectionError, TimeoutError, OllamaServiceError))
                )
                def execute_tool_with_retries(tool_name: str, tool_params: dict, step_title: str):
                    """Ejecutar herramienta con reintentos autom√°ticos - SOLO EJECUCI√ìN REAL"""
                    logger.info(f"üîÑ Intentando ejecutar herramienta '{tool_name}' para el paso: {step_title}")
                    
                    if tool_name == 'web_search':
                        if not tool_manager or not hasattr(tool_manager, 'execute_tool'):
                            raise ToolNotAvailableError(f"Tool manager no disponible o herramienta 'web_search' no inicializada.")
                        return tool_manager.execute_tool('web_search', tool_params, task_id=task_id)
                    
                    elif tool_name in ['analysis', 'creation', 'planning', 'delivery', 'processing', 'synthesis', 'search_definition', 'data_analysis']:
                        if not ollama_service or not ollama_service.is_healthy():
                            raise OllamaServiceError("Ollama service no est√° disponible o no es saludable.")
                        
                        # Para herramientas basadas en Ollama, la l√≥gica de prompt debe ser robusta
                        result = ollama_service.generate_response(tool_params.get('prompt', ''), tool_params.get('ollama_options', {}))
                        
                        # Verificar que la respuesta de Ollama no sea un error
                        if result.get('error'):
                            raise OllamaServiceError(f"Error en Ollama: {result['error']}")
                        
                        return result
                    
                    else:
                        # Para herramientas no expl√≠citamente manejadas, intentar con tool_manager
                        if not tool_manager or not hasattr(tool_manager, 'execute_tool'):
                            raise ToolNotAvailableError(f"Herramienta '{tool_name}' no reconocida o no disponible.")
                        return tool_manager.execute_tool(tool_name, tool_params, task_id=task_id)
                
                try:
                    # EJECUTAR HERRAMIENTA REAL seg√∫n el tipo de paso con reintentos autom√°ticos
                    if step['tool'] == 'web_search' or 'b√∫squeda' in step['title'].lower():
                        search_query = extract_search_query_from_message(message, step['title'])
                        logger.info(f"üîç Executing web search with retries for: {search_query}")
                        
                        # Enviar detalle de ejecuci√≥n de herramienta
                        send_websocket_update('tool_execution_detail', {
                            'type': 'tool_execution_detail',
                            'tool_name': 'web_search',
                            'input_params': {'query': search_query, 'num_results': 5},
                            'message': f'üîç Buscando informaci√≥n: {search_query}',
                            'timestamp': datetime.now().isoformat()
                        })
                        
                        try:
                            # Usar ejecuci√≥n con reintentos autom√°ticos
                            result = execute_tool_with_retries('web_search', {
                                'query': search_query,
                                'num_results': 5
                            }, step['title'])
                            
                            step_result = {
                                'type': 'web_search',
                                'query': search_query,
                                'results': result.get('search_results', []),
                                'summary': f"Encontradas {len(result.get('search_results', []))} fuentes relevantes"
                            }
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            
                            # Enviar resultado de herramienta
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'web_search',
                                'output_summary': step_result['summary'],
                                'message': f'‚úÖ B√∫squeda completada: {step_result["summary"]}',
                                'timestamp': datetime.now().isoformat()
                            })
                            
                            logger.info(f"‚úÖ Web search completed: {len(result.get('search_results', []))} results")
                            
                        except Exception as search_error:
                            logger.error(f"‚ùå Web search failed after retries: {str(search_error)}")
                            
                            # Enviar error detallado
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'web_search',
                                'error': str(search_error),
                                'message': f'‚ùå Error en b√∫squeda despu√©s de reintentos: {str(search_error)}',
                                'timestamp': datetime.now().isoformat()
                            })
                            
                            # Estrategia de fallback para herramientas cr√≠ticas
                            logger.info(f"üîÑ Attempting fallback search strategy for: {search_query}")
                            step_result = {
                                'type': 'web_search_fallback',
                                'query': search_query,
                                'results': [],
                                'summary': f"B√∫squeda no completada. Contin√∫o con informaci√≥n disponible.",
                                'error': str(search_error),
                                'fallback_used': True
                            }
                            step['result'] = step_result
                            final_results.append(step_result)
                    
                    elif step['tool'] == 'analysis' or 'an√°lisis' in step['title'].lower():
                        logger.info(f"üß† Executing analysis using REAL execution")
                        
                        # Enviar detalle de ejecuci√≥n de herramienta
                        send_websocket_update('tool_execution_detail', {
                            'type': 'tool_execution_detail',
                            'tool_name': 'analysis',
                            'input_params': {'context': step['description']},
                            'message': f'üß† Ejecutando an√°lisis: {step["title"]}',
                            'timestamp': datetime.now().isoformat()
                        })
                        
                        # Generar an√°lisis espec√≠fico usando contexto previo
                        analysis_context = f"Tarea: {message}\nPaso actual: {step['title']}\nDescripci√≥n: {step['description']}"
                        if final_results:
                            analysis_context += f"\nResultados previos: {final_results[-1] if final_results else 'Ninguno'}"
                        
                        analysis_prompt = f"""
Realiza un an√°lisis detallado para:
{analysis_context}

Proporciona:
1. An√°lisis espec√≠fico del contexto
2. Hallazgos principales
3. Recomendaciones para pr√≥ximos pasos
4. Conclusiones preliminares

Formato: Respuesta estructurada y profesional.
"""
                        
                        try:
                            # EJECUCI√ìN REAL CON REINTENTOS - NO SIMULACI√ìN
                            result = execute_tool_with_retries('analysis', {
                                'prompt': analysis_prompt,
                                'ollama_options': {}
                            }, step['title'])
                            
                            step_result = {
                                'type': 'analysis',
                                'content': result.get('response', 'An√°lisis completado'),
                                'summary': 'An√°lisis detallado generado exitosamente'
                            }
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            
                            # Enviar resultado de herramienta
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'analysis',
                                'output_summary': step_result['summary'],
                                'message': f'‚úÖ An√°lisis completado: {step["title"]}',
                                'timestamp': datetime.now().isoformat()
                            })
                            
                            logger.info(f"‚úÖ Analysis completed successfully")
                            
                        except (OllamaServiceError, ToolNotAvailableError) as analysis_error:
                            logger.error(f"‚ùå Analysis failed after retries: {str(analysis_error)}")
                            
                            # Marcar paso como fallido sin simulaci√≥n
                            step_result = {
                                'type': 'analysis_failed',
                                'error': str(analysis_error),
                                'summary': f'‚ùå Error en an√°lisis: {str(analysis_error)}',
                                'fallback_used': True
                            }
                            step['result'] = step_result
                            step['status'] = 'failed'
                            final_results.append(step_result)
                            
                            # Enviar error detallado
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'analysis',
                                'error': str(analysis_error),
                                'message': f'‚ùå Error en an√°lisis: {str(analysis_error)}',
                                'timestamp': datetime.now().isoformat()
                            })
                    
                    elif step['tool'] == 'creation' or 'creaci√≥n' in step['title'].lower() or 'desarrollo' in step['title'].lower():
                        logger.info(f"üõ†Ô∏è Executing creation with REAL file generation - NO SIMULATION")
                        
                        # Enviar detalle de ejecuci√≥n de herramienta
                        send_websocket_update('tool_execution_detail', {
                            'type': 'tool_execution_detail',
                            'tool_name': 'creation',
                            'input_params': {'task': step['title']},
                            'message': f'üõ†Ô∏è Creando contenido y archivo: {step["title"]}',
                            'timestamp': datetime.now().isoformat()
                        })
                        
                        # Generar contenido espec√≠fico
                        creation_context = f"Tarea: {message}\nPaso: {step['title']}\nDescripci√≥n: {step['description']}"
                        if final_results:
                            creation_context += f"\nInformaci√≥n previa: {final_results}"
                        
                        # PROMPT ULTRA ESPEC√çFICO PARA EVITAR PLANES DE ACCI√ìN
                        if 'archivo' in message.lower() and ('contenga' in message.lower() or 'texto' in message.lower()):
                            # Para solicitudes de archivos simples con contenido espec√≠fico
                            import re
                            content_match = re.search(r'contenga[^:]*[:]\s*(.+?)(?:\.|$|")', message, re.IGNORECASE)
                            if content_match:
                                requested_content = content_match.group(1).strip()
                                creation_prompt = f"""
INSTRUCCI√ìN: Responde √öNICAMENTE con el contenido exacto solicitado. NO generes planes de acci√≥n.

CONTENIDO EXACTO A GENERAR: {requested_content}

Responde SOLO con: {requested_content}
"""
                            else:
                                creation_prompt = f"""
IMPORTANTE: NO generes un plan de acci√≥n. Genera el CONTENIDO REAL solicitado.

Tarea: {message}

Responde con el contenido exacto que el usuario solicit√≥, NO con un plan de c√≥mo hacerlo.
"""
                        else:
                            creation_prompt = f"""
IMPORTANTE: NO generes un plan de acci√≥n. Genera el CONTENIDO REAL solicitado.

{creation_context}

INSTRUCCI√ìN CR√çTICA: Responde con el contenido final que se solicita, NO con pasos de c√≥mo crearlo.

Genera el contenido espec√≠fico, detallado y profesional que se solicita DIRECTAMENTE.
"""
                        
                        try:
                            # EJECUCI√ìN REAL CON REINTENTOS - NO SIMULACI√ìN
                            result = execute_tool_with_retries('creation', {
                                'prompt': creation_prompt,
                                'ollama_options': {}
                            }, step['title'])
                            
                            content = result.get('response', 'Contenido creado')
                            
                            # üÜï CREAR ARCHIVO REAL TANGIBLE - VALIDACI√ìN RIGUROSA
                            try:
                                # Determinar tipo de archivo basado en la tarea
                                file_extension = '.md'  # Por defecto markdown
                                if 'documento' in message.lower() or 'informe' in message.lower():
                                    file_extension = '.md'
                                elif 'c√≥digo' in message.lower() or 'script' in message.lower():
                                    file_extension = '.py'
                                elif 'plan' in message.lower():
                                    file_extension = '.txt'
                                
                                # Crear nombre de archivo √∫nico
                                import re
                                safe_title = re.sub(r'[^a-zA-Z0-9\-_]', '_', step['title'][:30])
                                filename = f"{safe_title}_{int(time.time())}{file_extension}"
                                file_path = f"/app/backend/static/generated_files/{filename}"
                                
                                # Crear directorio si no existe
                                os.makedirs("/app/backend/static/generated_files", exist_ok=True)
                                
                                # Escribir archivo real
                                with open(file_path, 'w', encoding='utf-8') as f:
                                    f.write(content)
                                
                                # VALIDACI√ìN RIGUROSA - PROBLEMA 8 IMPLEMENTADO PARCIALMENTE
                                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                                    file_size = os.path.getsize(file_path)
                                    logger.info(f"‚úÖ ARCHIVO REAL CREADO Y VALIDADO: {filename} ({file_size} bytes)")
                                    
                                    step_result = {
                                        'type': 'creation',
                                        'content': content,
                                        'summary': f'‚úÖ Archivo creado y validado exitosamente: {filename}',
                                        'file_created': True,
                                        'file_path': file_path,
                                        'file_name': filename,
                                        'file_size': file_size,
                                        'download_url': f'/api/download/{filename}',
                                        'tangible_result': True
                                    }
                                    
                                    # Enviar notificaci√≥n de archivo creado
                                    send_websocket_update('tool_execution_detail', {
                                        'type': 'tool_execution_detail',
                                        'tool_name': 'creation',
                                        'output_summary': f'‚úÖ Archivo creado y validado: {filename} ({file_size} bytes)',
                                        'file_created': filename,
                                        'download_url': f'/api/download/{filename}',
                                        'message': f'‚úÖ Archivo generado, validado y listo para descargar: {filename}',
                                        'timestamp': datetime.now().isoformat()
                                    })
                                    
                                else:
                                    raise FileCreationError("El archivo no se pudo crear correctamente o est√° vac√≠o")
                                
                            except Exception as file_error:
                                logger.error(f"‚ùå Error creando archivo real: {str(file_error)}")
                                raise FileCreationError(f"Error en creaci√≥n de archivo: {str(file_error)}")
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            logger.info(f"‚úÖ Content creation with REAL file generation completed")
                            
                        except (OllamaServiceError, ToolNotAvailableError, FileCreationError) as creation_error:
                            logger.error(f"‚ùå Creation failed after retries: {str(creation_error)}")
                            
                            # Marcar paso como fallido sin simulaci√≥n
                            step_result = {
                                'type': 'creation_failed',
                                'error': str(creation_error),
                                'summary': f'‚ùå Error en creaci√≥n: {str(creation_error)}',
                                'file_created': False,
                                'fallback_used': True
                            }
                            step['result'] = step_result
                            step['status'] = 'failed'
                            final_results.append(step_result)
                            
                            # Enviar error detallado
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'creation',
                                'error': str(creation_error),
                                'message': f'‚ùå Error en creaci√≥n: {str(creation_error)}',
                                'timestamp': datetime.now().isoformat()
                            })
                    
                    elif step['tool'] == 'planning' or 'planificaci√≥n' in step['title'].lower():
                        logger.info(f"üìã Executing planning with REAL plan generation - NO SIMULATION")
                        
                        # Enviar detalle de ejecuci√≥n de herramienta
                        send_websocket_update('tool_execution_detail', {
                            'type': 'tool_execution_detail',
                            'tool_name': 'planning',
                            'input_params': {'context': step['description']},
                            'message': f'üìã Ejecutando planificaci√≥n: {step["title"]}',
                            'timestamp': datetime.now().isoformat()
                        })
                        
                        # Generar plan espec√≠fico usando contexto previo
                        planning_context = f"Tarea: {message}\nPaso: {step['title']}\nDescripci√≥n: {step['description']}"
                        if final_results:
                            planning_context += f"\nResultados anteriores: {final_results}"
                        
                        planning_prompt = f"""
Desarrolla un plan espec√≠fico para:
{planning_context}

Incluye:
1. Objetivos espec√≠ficos del plan
2. Estrategias detalladas
3. Recursos necesarios
4. Cronograma estimado
5. M√©tricas de √©xito

Formato: Plan estructurado y profesional.
"""
                        
                        try:
                            # EJECUCI√ìN REAL CON REINTENTOS - NO SIMULACI√ìN
                            result = execute_tool_with_retries('planning', {
                                'prompt': planning_prompt,
                                'ollama_options': {}
                            }, step['title'])
                            
                            step_result = {
                                'type': 'planning',
                                'content': result.get('response', 'Plan generado'),
                                'summary': 'Plan detallado generado exitosamente'
                            }
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            
                            # Enviar resultado de herramienta
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'planning',
                                'output_summary': step_result['summary'],
                                'message': f'‚úÖ Planificaci√≥n completada: {step["title"]}',
                                'timestamp': datetime.now().isoformat()
                            })
                            
                            logger.info(f"‚úÖ Planning completed successfully")
                            
                        except (OllamaServiceError, ToolNotAvailableError) as planning_error:
                            logger.error(f"‚ùå Planning failed after retries: {str(planning_error)}")
                            
                            # Marcar paso como fallido sin simulaci√≥n
                            step_result = {
                                'type': 'planning_failed',
                                'error': str(planning_error),
                                'summary': f'‚ùå Error en planificaci√≥n: {str(planning_error)}',
                                'fallback_used': True
                            }
                            step['result'] = step_result
                            step['status'] = 'failed'
                            final_results.append(step_result)
                            
                            # Enviar error detallado
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'planning',
                                'error': str(planning_error),
                                'message': f'‚ùå Error en planificaci√≥n: {str(planning_error)}',
                                'timestamp': datetime.now().isoformat()
                            })
                    
                    elif step['tool'] == 'delivery' or 'entrega' in step['title'].lower():
                        if ollama_service:
                            logger.info(f"üì¶ Executing final delivery with TANGIBLE results")
                            
                            # Generar entrega final con todos los resultados
                            delivery_prompt = f"""
Prepara la entrega final para la tarea: {message}

Consolida todos los resultados obtenidos:
{final_results}

Crea un documento de entrega final que incluya:
1. RESUMEN EJECUTIVO de lo realizado
2. RESULTADOS PRINCIPALES obtenidos
3. CONTENIDO COMPLETO generado
4. ARCHIVOS Y ENTREGABLES creados
5. CONCLUSIONES Y RECOMENDACIONES
6. ENTREGABLES FINALES disponibles

Formato: Documento profesional completo y estructurado.
"""
                            
                            result = ollama_service.generate_response(delivery_prompt, {})
                            content = result.get('response', 'Entrega completada')
                            
                            # üÜï CREAR RESUMEN EJECUTIVO COMO ARCHIVO
                            try:
                                # Crear resumen ejecutivo como archivo tangible
                                import re
                                safe_message = re.sub(r'[^a-zA-Z0-9\-_]', '_', message[:30])
                                filename = f"Resumen_Ejecutivo_{safe_message}_{int(time.time())}.md"
                                file_path = f"/app/backend/static/generated_files/{filename}"
                                
                                # Crear directorio si no existe
                                os.makedirs("/app/backend/static/generated_files", exist_ok=True)
                                
                                # Preparar contenido del resumen ejecutivo
                                executive_summary = f"""# RESUMEN EJECUTIVO
## Tarea: {message}
## Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M')}

{content}

## ARCHIVOS GENERADOS
"""
                                
                                # Agregar lista de archivos creados
                                files_created = []
                                for result_item in final_results:
                                    if isinstance(result_item, dict) and result_item.get('file_created'):
                                        files_created.append(f"- {result_item['file_name']} ({result_item['file_size']} bytes)")
                                        executive_summary += f"- {result_item['file_name']} ({result_item['file_size']} bytes)\n"
                                
                                if not files_created:
                                    executive_summary += "- No se crearon archivos adicionales en este proceso\n"
                                
                                executive_summary += f"""
## ESTAD√çSTICAS
- Pasos ejecutados: {len(steps)}
- Resultados generados: {len(final_results)}
- Archivos creados: {len(files_created)}
- Estado: ‚úÖ Completado exitosamente
"""
                                
                                # Escribir archivo de resumen
                                with open(file_path, 'w', encoding='utf-8') as f:
                                    f.write(executive_summary)
                                
                                # Verificar creaci√≥n
                                if os.path.exists(file_path):
                                    file_size = os.path.getsize(file_path)
                                    logger.info(f"‚úÖ RESUMEN EJECUTIVO CREADO: {filename} ({file_size} bytes)")
                                    
                                    step_result = {
                                        'type': 'delivery',
                                        'content': content,
                                        'summary': f'‚úÖ Tarea completada con entrega final: {filename}',
                                        'final_deliverable': True,
                                        'file_created': True,
                                        'file_path': file_path,
                                        'file_name': filename,
                                        'file_size': file_size,
                                        'download_url': f'/api/download/{filename}',
                                        'executive_summary': True,
                                        'total_files_created': len(files_created) + 1  # +1 por el propio resumen
                                    }
                                    
                                    # Enviar notificaci√≥n de entrega final
                                    send_websocket_update('tool_execution_detail', {
                                        'type': 'tool_execution_detail',
                                        'tool_name': 'delivery',
                                        'output_summary': f'‚úÖ Entrega final completada: {filename}',
                                        'file_created': filename,
                                        'download_url': f'/api/download/{filename}',
                                        'total_files': len(files_created) + 1,
                                        'message': f'üéâ Entrega final completada con {len(files_created) + 1} archivo(s) generado(s)',
                                        'timestamp': datetime.now().isoformat()
                                    })
                                    
                                else:
                                    raise Exception("No se pudo crear el resumen ejecutivo")
                                    
                            except Exception as file_error:
                                logger.error(f"‚ùå Error creando resumen ejecutivo: {str(file_error)}")
                                step_result = {
                                    'type': 'delivery',
                                    'content': content,
                                    'summary': 'Tarea completada exitosamente con entrega final',
                                    'final_deliverable': True,
                                    'file_error': str(file_error)
                                }
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            logger.info(f"‚úÖ Final delivery with tangible results completed")
                        # Si llegamos aqu√≠, Ollama no est√° disponible para delivery
                        logger.error(f"‚ùå Ollama service not available for delivery step: {step['title']}")
                        
                        # En lugar de simulaci√≥n, marcar como fallido
                        step_result = {
                            'type': 'delivery_failed',
                            'error': 'Ollama service not available',
                            'summary': '‚ùå Error: No se pudo completar la entrega - Ollama no disponible',
                            'file_created': False,
                            'fallback_used': True
                        }
                        step['result'] = step_result
                        step['status'] = 'failed'
                        final_results.append(step_result)
                        
                        # Enviar error detallado
                        send_websocket_update('tool_execution_detail', {
                            'type': 'tool_execution_detail',
                            'tool_name': 'delivery',
                            'error': 'Ollama service not available',
                            'message': '‚ùå Error en entrega final: Ollama no disponible',
                            'timestamp': datetime.now().isoformat()
                        })
                    
                    else:
                        # Paso gen√©rico - ejecutar con REAL Ollama execution - NO SIMULATION
                        try:
                            logger.info(f"‚ö° Executing generic step with REAL execution: {step['title']}")
                            
                            generic_prompt = f"""
Ejecuta el paso '{step['title']}' para la tarea: {message}

Descripci√≥n: {step['description']}
Contexto previo: {final_results if final_results else 'Inicio de tarea'}

Proporciona un resultado espec√≠fico y √∫til para este paso.
"""
                            
                            # EJECUCI√ìN REAL CON REINTENTOS - NO SIMULACI√ìN
                            result = execute_tool_with_retries('processing', {
                                'prompt': generic_prompt,
                                'ollama_options': {}
                            }, step['title'])
                            
                            step_result = {
                                'type': 'generic',
                                'content': result.get('response', 'Paso completado'),
                                'summary': f"Paso '{step['title']}' completado exitosamente"
                            }
                            
                            step['result'] = step_result
                            final_results.append(step_result)
                            logger.info(f"‚úÖ Generic step completed successfully: {step['title']}")
                            
                        except (OllamaServiceError, ToolNotAvailableError) as generic_error:
                            logger.error(f"‚ùå Generic step failed after retries: {str(generic_error)}")
                            
                            # Marcar paso como fallido sin simulaci√≥n
                            step_result = {
                                'type': 'generic_failed',
                                'error': str(generic_error),
                                'summary': f'‚ùå Error en paso gen√©rico: {str(generic_error)}',
                                'fallback_used': True
                            }
                            step['result'] = step_result
                            step['status'] = 'failed'
                            final_results.append(step_result)
                            
                            # Enviar error detallado
                            send_websocket_update('tool_execution_detail', {
                                'type': 'tool_execution_detail',
                                'tool_name': 'processing',
                                'error': str(generic_error),
                                'message': f'‚ùå Error en paso gen√©rico: {str(generic_error)}',
                                'timestamp': datetime.now().isoformat()
                            })
                    
                    # üÜï PROBLEMA 2: VALIDACI√ìN RIGUROSA DE RESULTADOS ANTES DE MARCAR COMO COMPLETADO
                    step_execution_time = time.time() - step_start_time
                    
                    # Solo marcar como completado si tenemos un step_result v√°lido
                    if step_result and 'status' not in step or step.get('status') != 'failed':
                        # VALIDAR RESULTADO USANDO SISTEMA ROBUSTO
                        validation_status, validation_message = validate_step_result(step['tool'], step_result)
                        
                        logger.info(f"üîç Validaci√≥n para {step['tool']}: {validation_status} - {validation_message}")
                        
                        # Actualizar step_result con informaci√≥n de validaci√≥n
                        step_result['validation_status'] = validation_status
                        step_result['validation_message'] = validation_message
                        
                        # Establecer estado del paso basado en validaci√≥n
                        if validation_status == 'success':
                            step['status'] = StepStatus.COMPLETED_SUCCESS
                            step['completed'] = True
                            websocket_status = 'completed_success'
                        elif validation_status == 'warning':
                            step['status'] = StepStatus.COMPLETED_WITH_WARNINGS  
                            step['completed'] = True
                            websocket_status = 'completed_with_warnings'
                        else:  # validation_status == 'failure'
                            step['status'] = StepStatus.FAILED
                            step['completed'] = False
                            websocket_status = 'failed'
                            
                        step['active'] = False
                        step['result'] = step_result
                        
                        # Enviar actualizaci√≥n de paso con estado detallado
                        send_websocket_update('step_update', {
                            'type': 'step_update',
                            'step_id': step['id'],
                            'status': websocket_status,
                            'title': step['title'],
                            'description': step['description'],
                            'result_summary': validation_message,  # Usar mensaje de validaci√≥n como resumen
                            'execution_time': step_execution_time,
                            'progress': ((i + 1) / len(steps)) * 100,
                            'validation_status': validation_status
                        })
                        
                        # Log detallado basado en validaci√≥n
                        if validation_status == 'success':
                            send_websocket_update('log_message', {
                                'type': 'log_message',
                                'level': 'info',
                                'message': f'‚úÖ Paso {i+1}/{len(steps)} completado exitosamente: {step["title"]} - {validation_message} ({step_execution_time:.1f}s)',
                                'timestamp': datetime.now().isoformat()
                            })
                            logger.info(f"‚úÖ Step {i+1} VALIDATED AND COMPLETED successfully: {step['title']} in {step_execution_time:.1f}s")
                        elif validation_status == 'warning':
                            send_websocket_update('log_message', {
                                'type': 'log_message',
                                'level': 'warning', 
                                'message': f'‚ö†Ô∏è Paso {i+1}/{len(steps)} completado con advertencias: {step["title"]} - {validation_message} ({step_execution_time:.1f}s)',
                                'timestamp': datetime.now().isoformat()
                            })
                            logger.warning(f"‚ö†Ô∏è Step {i+1} COMPLETED WITH WARNINGS: {step['title']} - {validation_message}")
                        else:
                            send_websocket_update('log_message', {
                                'type': 'log_message',
                                'level': 'error',
                                'message': f'‚ùå Paso {i+1}/{len(steps)} fall√≥ en validaci√≥n: {step["title"]} - {validation_message} ({step_execution_time:.1f}s)',
                                'timestamp': datetime.now().isoformat()
                            })
                            logger.error(f"‚ùå Step {i+1} FAILED VALIDATION: {step['title']} - {validation_message}")
                    else:
                        # Paso ya marcado como fallido o sin resultado v√°lido
                        step['active'] = False
                        if not step.get('status'):
                            step['status'] = StepStatus.FAILED
                            step['completed'] = False
                        
                        send_websocket_update('step_update', {
                            'type': 'step_update',
                            'step_id': step['id'],
                            'status': 'failed',
                            'title': step['title'],
                            'description': step['description'],
                            'result_summary': step.get('error', 'Paso fall√≥ durante ejecuci√≥n'),
                            'execution_time': step_execution_time,
                            'progress': ((i + 1) / len(steps)) * 100
                        })
                        
                        logger.error(f"‚ùå Step {i+1} FAILED during execution: {step['title']}")
                    
                    
                    # ELIMINADO: Pausa simulada entre pasos
                    # Ahora el progreso se muestra en tiempo real sin pausas artificiales
                    
                except Exception as step_error:
                    step_execution_time = time.time() - step_start_time
                    logger.error(f"‚ùå Error in step {i+1}: {str(step_error)}")
                    step['completed'] = False
                    step['active'] = False
                    step['status'] = 'failed'
                    step['error'] = str(step_error)
                    
                    # Enviar actualizaci√≥n de paso fallido en tiempo real
                    send_websocket_update('step_update', {
                        'type': 'step_update',
                        'step_id': step['id'],
                        'status': 'failed',
                        'title': step['title'],
                        'description': step['description'],
                        'error': str(step_error),
                        'execution_time': step_execution_time
                    })
                    
                    # Enviar log de error
                    send_websocket_update('log_message', {
                        'type': 'log_message',
                        'level': 'error',
                        'message': f'‚ùå Error en paso {i+1}/{len(steps)}: {step["title"]} - {str(step_error)}',
                        'timestamp': datetime.now().isoformat()
                    })
                
                # Actualizar plan en memoria y persistencia con estados granulares
                task_manager = get_task_manager()
                task_manager.update_task_step_status(
                    task_id,
                    step['id'],
                    step.get('status', StepStatus.FAILED),  # Usar estado granular
                    step_result.get('validation_message') if step_result else step.get('error'),
                    step.get('error') if step.get('status') == StepStatus.FAILED else None
                )
                update_task_data(task_id, {'plan': steps})
            
            # GENERAR RESULTADO FINAL CONSOLIDADO
            if final_results:
                logger.info(f"üéØ Generating final consolidated result for task {task_id}")
                
                try:
                    if ollama_service:
                        final_prompt = f"""
TAREA COMPLETADA: {message}

RESULTADOS OBTENIDOS:
{final_results}

Genera un RESULTADO FINAL CONSOLIDADO que incluya:

1. üéØ RESUMEN EJECUTIVO
   - Qu√© se solicit√≥
   - Qu√© se logr√≥
   - Calidad del resultado

2. üìã ENTREGABLES PRINCIPALES
   - Lista clara de lo que se entreg√≥
   - Resultados espec√≠ficos obtenidos

3. üîç HALLAZGOS CLAVE (si aplica)
   - Informaci√≥n importante encontrada
   - Insights relevantes

4. ‚úÖ CONCLUSIONES
   - Evaluaci√≥n del √©xito de la tarea
   - Recomendaciones adicionales

Formato: Profesional, estructurado y completo.
"""
                        
                        final_result = ollama_service.generate_response(final_prompt, {})
                        
                        # Guardar resultado final
                        active_task_plans[task_id]['final_result'] = {
                            'content': final_result.get('response', 'Tarea completada exitosamente'),
                            'completed_at': datetime.now().isoformat(),
                            'total_steps': len(steps),
                            'all_results': final_results
                        }
                        
                        logger.info(f"‚úÖ Final consolidated result generated for task {task_id}")
                        
                except Exception as e:
                    logger.error(f"Error generating final result: {str(e)}")
                    active_task_plans[task_id]['final_result'] = {
                        'content': 'Tarea completada con algunos errores en la consolidaci√≥n final',
                        'completed_at': datetime.now().isoformat(),
                        'total_steps': len(steps),
                        'error': str(e)
                    }
            
            # üÜï PROBLEMA 2: DETERMINACI√ìN INTELIGENTE DE ESTADO FINAL USANDO VALIDACI√ìN GRANULAR
            final_task_status = determine_task_status_from_steps(steps)
            
            # Estad√≠sticas detalladas para logging y respuesta
            success_steps = sum(1 for step in steps if step.get('status') == StepStatus.COMPLETED_SUCCESS)
            warning_steps = sum(1 for step in steps if step.get('status') == StepStatus.COMPLETED_WITH_WARNINGS)
            failed_steps = sum(1 for step in steps if step.get('status') == StepStatus.FAILED)
            total_steps = len(steps)
            
            # Calcular completed_steps para compatibilidad con c√≥digo existente
            completed_steps = success_steps + warning_steps
            
            logger.info(f"üìä TASK COMPLETION STATS - Success: {success_steps}, Warnings: {warning_steps}, Failed: {failed_steps}, Total: {total_steps}")
            logger.info(f"üéØ FINAL TASK STATUS: {final_task_status}")
            
            # Generar respuesta final din√°mica basada en estado real y validaci√≥n
            failed_step_details = []
            warning_step_details = []
            
            for step in steps:
                if step.get('status') == StepStatus.FAILED:
                    failed_step_details.append({
                        'title': step.get('title', 'Paso desconocido'),
                        'error': step.get('error', 'Error desconocido'),
                        'validation_message': step.get('result', {}).get('validation_message', '')
                    })
                elif step.get('status') == StepStatus.COMPLETED_WITH_WARNINGS:
                    warning_step_details.append({
                        'title': step.get('title', 'Paso con advertencias'),
                        'warning': step.get('result', {}).get('validation_message', 'Advertencia no especificada')
                    })
            
            # Construir mensaje de errores y advertencias para respuesta
            error_message = None
            warnings = []
            
            if failed_step_details:
                error_message = f"{len(failed_step_details)} paso(s) fallaron: " + ", ".join([f"'{detail['title']}'" for detail in failed_step_details])
            
            if warning_step_details:
                warnings = [f"'{detail['title']}': {detail['warning']}" for detail in warning_step_details]
            
            # Mantener compatibilidad con c√≥digo existente - generar failed_step_titles
            failed_step_titles = [detail['title'] for detail in failed_step_details]
            final_dynamic_response = generate_clean_response(
                ollama_response="",
                tool_results=final_results,
                task_status=final_task_status,
                failed_step_title=failed_step_titles[0] if failed_step_titles else None,
                error_message=error_message,
                warnings=warnings  # üÜï Pasar advertencias detalladas
            )
            
            # Marcar tarea como completada en persistencia y memoria
            task_completion_updates = {
                'status': 'completed',
                'completed_at': datetime.now().isoformat(),
                'final_result': final_dynamic_response,  # Usar respuesta din√°mica
                'final_task_status': final_task_status,
                'completed_steps': completed_steps,
                'failed_steps': failed_steps,
                'total_steps': total_steps
            }
            
            # Actualizar con TaskManager (persistencia)
            update_task_data(task_id, task_completion_updates)
            
            # Tambi√©n actualizar memoria legacy por compatibilidad
            if task_id in active_task_plans:
                active_task_plans[task_id].update(task_completion_updates)
            
            # Enviar notificaci√≥n de finalizaci√≥n del plan con estado real
            send_websocket_update('task_completed', {
                'type': 'task_completed',
                'task_id': task_id,
                'status': 'success' if final_task_status == "completed_success" else 'completed_with_warnings',
                'final_result': final_dynamic_response,
                'final_task_status': final_task_status,
                'total_steps': total_steps,
                'completed_steps': completed_steps,
                'failed_steps': failed_steps,
                'execution_time': (datetime.now() - active_task_plans[task_id].get('start_time', datetime.now())).total_seconds(),
                'message': f'üéâ Tarea completada: {completed_steps}/{total_steps} pasos exitosos',
                'timestamp': datetime.now().isoformat()
            })
            
            # Enviar log final
            send_websocket_update('log_message', {
                'type': 'log_message',
                'level': 'info',
                'message': f'üéâ Tarea {task_id} completada con √©xito - {len(steps)} pasos ejecutados',
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"üéâ Task {task_id} completed successfully with REAL execution and final delivery!")
        
        # Ejecutar en hilo separado
        thread = threading.Thread(target=execute_steps)
        thread.daemon = True
        thread.start()
        
        logger.info(f"üöÄ Started REAL plan execution for task {task_id}")
        
    except Exception as e:
        logger.error(f"Error in real plan execution: {str(e)}")
        
        # Generar respuesta final de error din√°mica
        error_response = generate_clean_response(
            ollama_response="",
            tool_results=[],
            task_status="failed",
            failed_step_title="Ejecuci√≥n general",
            error_message=str(e)
        )
        
        # Enviar notificaci√≥n de fallo de tarea si WebSocket est√° disponible
        try:
            from src.websocket.websocket_manager import get_websocket_manager
            websocket_manager = get_websocket_manager()
            if websocket_manager and websocket_manager.is_initialized:
                websocket_manager.send_update(task_id, UpdateType.TASK_FAILED, {
                    'type': 'task_failed',
                    'task_id': task_id,
                    'status': 'failed',
                    'overall_error': str(e),
                    'final_result': error_response,  # Incluir respuesta din√°mica de error
                    'message': f'‚ùå Tarea fall√≥: {str(e)}',
                    'timestamp': datetime.now().isoformat()
                })
        except Exception:
            pass
        
        # Marcar como fallido con respuesta din√°mica
        if task_id in active_task_plans:
            active_task_plans[task_id]['status'] = 'failed'
            active_task_plans[task_id]['error'] = str(e)
            active_task_plans[task_id]['final_result'] = error_response

def extract_search_query_from_message(message: str, step_title: str) -> str:
    """
    Extrae una query de b√∫squeda optimizada usando LLM para mayor relevancia
    Mejora implementada seg√∫n UPGRADE.md Secci√≥n 4: Extracci√≥n de Query Mejorada (LLM-driven)
    """
    try:
        # Obtener servicio de Ollama para generaci√≥n inteligente de queries
        ollama_service = get_ollama_service()
        
        if not ollama_service or not ollama_service.is_healthy():
            logger.warning("‚ö†Ô∏è Ollama no disponible para extracci√≥n LLM de query, usando m√©todo heur√≠stico")
            return _fallback_query_extraction(message, step_title)
        
        # Prompt espec√≠fico para generar consultas de b√∫squeda optimizadas
        search_query_prompt = f"""Genera 3-5 palabras clave de b√∫squeda optimizadas para obtener informaci√≥n relevante y actualizada sobre esta tarea.

Mensaje original: "{message}"
Contexto del paso: "{step_title}"

INSTRUCCIONES:
- Extrae las palabras m√°s importantes y espec√≠ficas
- Enf√≥cate en t√©rminos t√©cnicos, nombres propios, conceptos clave
- Evita palabras gen√©ricas como "buscar", "informaci√≥n", "datos"  
- Incluye t√©rminos que ayuden a encontrar contenido actualizado
- Responde SOLO con las palabras clave separadas por comas
- M√°ximo 5 palabras clave relevantes

EJEMPLOS:
- "Analizar tendencias de IA en 2025" ‚Üí "inteligencia artificial, tendencias 2025, IA avances, machine learning"
- "Crear informe mercado criptomonedas" ‚Üí "criptomonedas, mercado crypto, bitcoin ethereum, an√°lisis 2025"

Palabras clave de b√∫squeda:"""

        logger.info(f"üîç Generating LLM-driven search query for: '{message[:30]}...'")
        
        # Llamar a Ollama con par√°metros optimizados para extracci√≥n de keywords
        response = ollama_service.generate_response(search_query_prompt, {
            'temperature': 0.3,  # Creatividad moderada
            'max_tokens': 100,   # Respuesta corta
            'response_format': 'text'
        })
        
        if response.get('error'):
            logger.warning(f"‚ö†Ô∏è Error en extracci√≥n LLM de query: {response['error']}")
            return _fallback_query_extraction(message, step_title)
        
        # Procesar respuesta de Ollama
        generated_keywords = response.get('response', '').strip()
        
        if generated_keywords and len(generated_keywords) > 5:
            # Limpiar la respuesta
            cleaned_query = generated_keywords.replace('\n', ' ').replace('"', '').strip()
            
            # Validar que las palabras clave no sean demasiado gen√©ricas
            generic_terms = ['informaci√≥n', 'datos', 'buscar', 'an√°lisis', 'crear', 'generar']
            keywords = [kw.strip() for kw in cleaned_query.split(',')]
            
            # Filtrar t√©rminos gen√©ricos y tomar los mejores
            relevant_keywords = [
                kw for kw in keywords 
                if len(kw) > 2 and not any(generic in kw.lower() for generic in generic_terms)
            ][:4]  # M√°ximo 4 keywords
            
            if relevant_keywords:
                final_query = ', '.join(relevant_keywords)
                logger.info(f"‚úÖ LLM-generated search query: '{final_query}'")
                return final_query
        
        logger.warning(f"‚ö†Ô∏è LLM query no v√°lida, usando fallback para: {message[:30]}...")
        return _fallback_query_extraction(message, step_title)
        
    except Exception as e:
        logger.error(f"‚ùå Error en extracci√≥n LLM de query: {str(e)}")
        return _fallback_query_extraction(message, step_title)

def _fallback_query_extraction(message: str, step_title: str) -> str:
    """
    M√©todo de respaldo heur√≠stico para extracci√≥n de query cuando LLM no est√° disponible
    """
    try:
        # Remover palabras comunes y conectores  
        stop_words = ['el', 'la', 'los', 'las', 'un', 'una', 'de', 'del', 'en', 'con', 'por', 'para', 'sobre', 'crear', 'buscar', 'dame', 'necesito', 'quiero', 'hacer']
        
        # Usar el mensaje original como base
        words = [word for word in message.lower().split() if word not in stop_words and len(word) > 2]
        
        # Agregar a√±o actual para b√∫squedas m√°s actualizadas
        current_year = "2025"
        if current_year not in ' '.join(words):
            words.append(current_year)
        
        # Tomar las primeras 4 palabras m√°s relevantes
        query = ' '.join(words[:4])
        
        # Si la query est√° vac√≠a, usar el t√≠tulo del paso
        if not query.strip():
            query = step_title.replace('B√∫squeda de', '').replace('informaci√≥n', '').strip()
            
        # Fallback final
        if not query.strip():
            # Extraer sustantivos y t√©rminos t√©cnicos del mensaje original
            import re
            technical_terms = re.findall(r'\b[A-Za-z]{4,}\b', message)
            if technical_terms:
                query = ' '.join(technical_terms[:3])
            else:
                query = message[:30]  # √öltimo recurso
        
        logger.info(f"üîÑ Fallback search query: '{query}'")
        return query
        
    except Exception:
        return message[:50]  # Fallback seguro

def generate_emergency_structured_plan(message: str, task_id: str, ollama_error: str) -> dict:
    """
    Genera un plan estructurado inteligente cuando Ollama falla completamente
    An√°lisis heur√≠stico mejorado del mensaje para crear plan espec√≠fico
    """
    logger.info(f"üÜò Generating emergency structured plan for task {task_id} due to Ollama failure: {ollama_error}")
    
    message_lower = message.lower().strip()
    
    # An√°lisis inteligente del tipo de tarea
    task_analysis = {
        'type': 'unknown',
        'tools': ['processing'],
        'steps': 1,
        'complexity': 'media'
    }
    
    # Detectar tipo de tarea principal
    if any(word in message_lower for word in ['buscar', 'investigar', 'encontrar', 'informaci√≥n', 'datos']):
        task_analysis.update({
            'type': 'investigaci√≥n',
            'tools': ['web_search', 'research', 'analysis'],
            'steps': 3,
            'complexity': 'media'
        })
    elif any(word in message_lower for word in ['crear', 'generar', 'escribir', 'desarrollar', 'hacer']):
        task_analysis.update({
            'type': 'creaci√≥n',
            'tools': ['planning', 'creation', 'delivery'],
            'steps': 3,
            'complexity': 'media'
        })
    elif any(word in message_lower for word in ['analizar', 'an√°lisis', 'estudiar', 'evaluar']):
        task_analysis.update({
            'type': 'an√°lisis',
            'tools': ['data_analysis', 'analysis', 'synthesis'],
            'steps': 3,
            'complexity': 'media'
        })
    elif any(word in message_lower for word in ['documento', 'informe', 'reporte', 'archivo']):
        task_analysis.update({
            'type': 'documentaci√≥n',
            'tools': ['planning', 'creation', 'delivery'],
            'steps': 3,
            'complexity': 'alta'
        })
    else:
        # Tarea general/procesamiento
        task_analysis.update({
            'type': 'procesamiento_general',
            'tools': ['processing', 'analysis'],
            'steps': 2,
            'complexity': 'baja'
        })
    
    # Construir plan estructurado basado en an√°lisis
    emergency_steps = []
    
    if task_analysis['type'] == 'investigaci√≥n':
        emergency_steps = [
            {
                "title": f"Buscar informaci√≥n sobre: {message[:50]}...",
                "description": f"Realizar b√∫squeda web detallada para obtener informaci√≥n relevante sobre la consulta del usuario",
                "tool": "web_search",
                "estimated_time": "2-3 minutos",
                "priority": "alta"
            },
            {
                "title": "Investigar fuentes adicionales",
                "description": "Realizar investigaci√≥n complementaria para obtener m√°s detalles y verificar informaci√≥n",
                "tool": "research", 
                "estimated_time": "2-3 minutos",
                "priority": "media"
            },
            {
                "title": "Analizar y sintetizar informaci√≥n",
                "description": "Procesar y analizar la informaci√≥n recopilada para generar respuesta completa",
                "tool": "analysis",
                "estimated_time": "1-2 minutos", 
                "priority": "alta"
            }
        ]
    elif task_analysis['type'] == 'creaci√≥n':
        emergency_steps = [
            {
                "title": f"Planificar creaci√≥n: {message[:40]}...",
                "description": "Establecer estructura y planificaci√≥n detallada para la creaci√≥n solicitada",
                "tool": "planning",
                "estimated_time": "1-2 minutos",
                "priority": "alta"
            },
            {
                "title": "Crear contenido principal",
                "description": f"Desarrollar y crear el contenido principal seg√∫n los requerimientos espec√≠ficos",
                "tool": "creation",
                "estimated_time": "3-5 minutos",
                "priority": "alta"
            },
            {
                "title": "Entregar resultado final",
                "description": "Formatear, revisar y entregar el resultado final de la creaci√≥n",
                "tool": "delivery",
                "estimated_time": "1-2 minutos",
                "priority": "media"
            }
        ]
    elif task_analysis['type'] == 'an√°lisis':
        emergency_steps = [
            {
                "title": f"Analizar datos: {message[:40]}...",
                "description": "Realizar an√°lisis detallado de los datos o informaci√≥n proporcionada",
                "tool": "data_analysis", 
                "estimated_time": "2-3 minutos",
                "priority": "alta"
            },
            {
                "title": "Procesar resultados anal√≠ticos",
                "description": "Interpretar y procesar los resultados del an√°lisis para obtener insights",
                "tool": "analysis",
                "estimated_time": "2-3 minutos",
                "priority": "alta"
            },
            {
                "title": "Sintetizar conclusiones",
                "description": "Sintetizar hallazgos y generar conclusiones claras y accionables",
                "tool": "synthesis",
                "estimated_time": "1-2 minutos",
                "priority": "media"
            }
        ]
    elif task_analysis['type'] == 'documentaci√≥n':
        emergency_steps = [
            {
                "title": f"Planificar documento: {message[:35]}...",
                "description": "Planificar estructura, contenido y formato del documento solicitado",
                "tool": "planning",
                "estimated_time": "1-2 minutos",
                "priority": "alta"
            },
            {
                "title": "Crear contenido del documento",
                "description": "Desarrollar el contenido principal del documento con informaci√≥n detallada",
                "tool": "creation",
                "estimated_time": "4-6 minutos",
                "priority": "alta"
            },
            {
                "title": "Finalizar y entregar documento",
                "description": "Revisar, formatear y entregar el documento final completo",
                "tool": "delivery",
                "estimated_time": "1-2 minutos",
                "priority": "media"
            }
        ]
    else:
        # Plan general de procesamiento
        emergency_steps = [
            {
                "title": f"Procesar solicitud: {message[:45]}...",
                "description": f"Procesar y atender la solicitud espec√≠fica del usuario de manera integral",
                "tool": "processing",
                "estimated_time": "2-3 minutos",
                "priority": "alta"
            },
            {
                "title": "Analizar y completar",
                "description": "Analizar los requerimientos y completar la tarea de manera satisfactoria",
                "tool": "analysis",
                "estimated_time": "1-2 minutos",
                "priority": "media"
            }
        ]
    
    # Calcular tiempo total estimado
    total_time_minutes = sum(int(step['estimated_time'].split('-')[0]) for step in emergency_steps if step['estimated_time'].split('-')[0].isdigit())
    total_time = f"{total_time_minutes}-{total_time_minutes + len(emergency_steps)} minutos"
    
    return {
        "steps": emergency_steps,
        "task_type": f"emergency_{task_analysis['type']}",
        "complexity": task_analysis['complexity'],
        "estimated_total_time": total_time
    }

def generate_task_title_with_llm(message: str, task_id: str) -> str:
    """
    Genera un t√≠tulo mejorado y profesional para la tarea usando LLM
    """
    logger.info(f"üìù Generating enhanced title for task {task_id} - Original: {message[:50]}...")
    
    # Obtener servicio de Ollama
    ollama_service = get_ollama_service()
    if not ollama_service or not ollama_service.is_healthy():
        logger.warning(f"‚ö†Ô∏è Ollama not available for title generation, using original message")
        return message.strip()
    
    try:
        # Prompt espec√≠fico para generar t√≠tulos profesionales
        title_prompt = f"""
Genera un T√çTULO PROFESIONAL, ESPEC√çFICO y CONCISO para esta tarea: "{message}"

INSTRUCCIONES:
- El t√≠tulo debe ser claro y descriptivo
- M√°ximo 60 caracteres
- Incluye elementos espec√≠ficos del dominio
- Debe sonar profesional y atractivo
- NO incluyas palabras gen√©ricas como "informaci√≥n", "datos"
- Capitaliza correctamente (formato t√≠tulo)

EJEMPLOS:
- "buscar informaci√≥n sobre IA" ‚Üí "An√°lisis de Tendencias en Inteligencia Artificial 2025"
- "crear un informe de ventas" ‚Üí "Informe de Rendimiento de Ventas Q1 2025"  
- "analizar el mercado" ‚Üí "Estudio de An√°lisis de Mercado Sectorial"

Responde √öNICAMENTE con el t√≠tulo, sin explicaciones adicionales.
"""
        
        response = ollama_service.generate_response(title_prompt, {
            'temperature': 0.3,  # Creativo pero controlado
            'max_tokens': 100,   # T√≠tulo corto
            'top_p': 0.9
        })
        
        if response.get('error'):
            logger.warning(f"‚ö†Ô∏è Error generating title with LLM: {response['error']}")
            return message.strip()
        
        # Limpiar y validar el t√≠tulo generado
        generated_title = response.get('response', '').strip()
        
        # Limpiar formato markdown o caracteres extra
        generated_title = generated_title.replace('**', '').replace('*', '')
        generated_title = generated_title.replace('"', '').replace("'", '')
        generated_title = generated_title.strip()
        
        # Validaciones
        if len(generated_title) == 0:
            logger.warning(f"‚ö†Ô∏è Empty title generated, using original message")
            return message.strip()
        
        if len(generated_title) > 80:
            generated_title = generated_title[:77] + "..."
        
        logger.info(f"‚úÖ Generated enhanced title for task {task_id}: '{generated_title}'")
        return generated_title
        
    except Exception as e:
        logger.error(f"‚ùå Error generating title with LLM: {str(e)}")
        return message.strip()

def generate_unified_ai_plan(message: str, task_id: str, attempt_retries: bool = True) -> dict:
    """
    Funci√≥n UNIFICADA para generaci√≥n de planes usando Ollama con robustecimiento y validaci√≥n de esquemas
    Consolidaci√≥n de generate_dynamic_plan_with_ai y generate_task_plan para eliminar duplicaci√≥n
    """
    logger.info(f"üß† Generating unified AI-powered plan for task {task_id} - Message: {message[:50]}...")
    
    # Obtener servicio de Ollama
    ollama_service = get_ollama_service()
    if not ollama_service:
        logger.error("‚ùå Ollama service not available for unified plan generation")
        return generate_fallback_plan_with_notification(message, task_id, "Ollama service not available")
    
    # Verificar que Ollama est√© saludable
    if not ollama_service.is_healthy():
        logger.error("‚ùå Ollama service not healthy for unified plan generation")
        return generate_fallback_plan_with_notification(message, task_id, "Ollama service not healthy")
    
    def validate_plan_schema(plan_data: dict) -> bool:
        """Validar que el plan cumple con el esquema requerido"""
        try:
            jsonschema.validate(plan_data, PLAN_SCHEMA)
            return True
        except jsonschema.ValidationError as e:
            logger.warning(f"‚ùå Plan schema validation failed for task {task_id}: {e.message}")
            return False
    
    def generate_plan_with_retries() -> dict:
        """Generar plan con reintentos y retroalimentaci√≥n espec√≠fica a Ollama"""
        max_attempts = 2 if attempt_retries else 1
        last_error = None
        
        for attempt in range(1, max_attempts + 1):
            try:
                logger.info(f"üîÑ Unified plan generation attempt {attempt}/{max_attempts} for task {task_id}")
                
                # Construir prompt espec√≠fico mejorado para generaci√≥n de JSON estructurado
                if attempt == 1:
                    # Primera tentativa: prompt espec√≠fico din√°mico
                    prompt = f"""
GENERA UN PLAN DE ACCI√ìN ULTRA-ESPEC√çFICO para esta tarea: "{message}"

INSTRUCCIONES CR√çTICAS:
- Analiza el tipo de tarea y dominio espec√≠fico
- Crea pasos √∫nicos que solo apliquen a esta tarea exacta
- NO uses t√©rminos gen√©ricos como "informaci√≥n", "an√°lisis", "documento"
- Identifica elementos espec√≠ficos del dominio (nombres propios, conceptos t√©cnicos, ubicaciones, etc.)
- Cada paso debe ser imposible de reutilizar para otra tarea

METODOLOG√çA ADAPTATIVA:
1. Identifica el dominio principal de la tarea
2. Extrae elementos espec√≠ficos √∫nicos (nombres, lugares, conceptos)
3. Crea pasos que incorporen estos elementos espec√≠ficos
4. Aseg√∫rate que cada paso sea altamente especializado

EJEMPLO DE TRANSFORMACI√ìN:
- En lugar de: "Buscar informaci√≥n sobre X"
- Mejor: "Identificar [elementos espec√≠ficos √∫nicos de X] en [fuentes espec√≠ficas del dominio]"

Responde √öNICAMENTE con un objeto JSON v√°lido siguiendo EXACTAMENTE este formato:

{{
  "steps": [
    {{
      "title": "Paso ULTRA-ESPEC√çFICO para esta tarea exacta (5-100 caracteres)",
      "description": "Acci√≥n concreta con elementos √∫nicos del dominio (10-300 caracteres)", 
      "tool": "web_search",
      "estimated_time": "Tiempo estimado como string",
      "priority": "alta|media|baja"
    }}
  ],
  "task_type": "Tipo de tarea espec√≠fico (m√≠nimo 3 caracteres)",
  "complexity": "baja|media|alta", 
  "estimated_total_time": "Tiempo total estimado"
}}

REGLAS ULTRA-CR√çTICAS:
- CADA paso debe incorporar elementos espec√≠ficos √∫nicos del dominio
- Evita completamente palabras gen√©ricas
- Adapta autom√°ticamente al contexto espec√≠fico de la tarea
- M√≠nimo 3 pasos, m√°ximo 6 pasos
- HERRAMIENTAS V√ÅLIDAS: web_search, analysis, creation, planning, delivery, processing, synthesis, search_definition, data_analysis, shell, research, investigation, web_scraping, search, mind_map, spreadsheets, database
- NO agregues texto adicional, solo el JSON
- Aseg√∫rate de que sea JSON v√°lido y parseable
"""
                elif attempt == 2:
                    # Segunda tentativa: prompt con correcci√≥n espec√≠fica y metodolog√≠a adaptativa
                    prompt = f"""
ATENCI√ìN: El JSON anterior tuvo errores. GENERA UN PLAN ULTRA-ESPEC√çFICO para: "{message}"

ERROR PREVIO: {last_error}

METODOLOG√çA ADAPTATIVA MEJORADA:
1. Analiza el dominio espec√≠fico de la tarea
2. Identifica elementos √∫nicos (t√©rminos t√©cnicos, nombres, ubicaciones espec√≠ficas)
3. Crea pasos que incorporen estos elementos espec√≠ficos del dominio
4. Evita completamente palabras gen√©ricas

PROCESO DE ESPECIALIZACI√ìN AUTOM√ÅTICA:
- Si es sobre tecnolog√≠a ‚Üí usa nombres espec√≠ficos de tecnolog√≠as, versiones, plataformas
- Si es sobre lugares ‚Üí usa nombres espec√≠ficos de ubicaciones, caracter√≠sticas locales
- Si es sobre negocios ‚Üí usa m√©tricas espec√≠ficas, herramientas del sector
- Si es sobre investigaci√≥n ‚Üí usa fuentes espec√≠ficas, metodolog√≠as del campo

Responde SOLO con JSON v√°lido usando EXACTAMENTE este formato:
{{
  "steps": [
    {{
      "title": "Paso especializado con elementos espec√≠ficos del dominio (5-100 caracteres)",
      "description": "Acci√≥n concreta incorporando conceptos √∫nicos de este tema (10-300 caracteres)", 
      "tool": "web_search",
      "estimated_time": "string",
      "priority": "media"
    }}
  ],
  "task_type": "string de m√≠nimo 3 caracteres",
  "complexity": "media",
  "estimated_total_time": "string"
}}

REGLAS ULTRA-CR√çTICAS:
- CADA paso debe incorporar elementos espec√≠ficos √∫nicos del dominio
- Evita completamente palabras gen√©ricas
- Adapta autom√°ticamente al contexto espec√≠fico de la tarea
- M√≠nimo 3 pasos, m√°ximo 6 pasos
- HERRAMIENTAS V√ÅLIDAS: web_search, analysis, creation, planning, delivery, processing, synthesis, search_definition, data_analysis, shell, research, investigation, web_scraping, search, mind_map, spreadsheets, database

SOLO JSON, sin explicaciones adicionales.
"""
                
                # Llamar a Ollama con par√°metros optimizados para JSON
                response = ollama_service.generate_response(prompt, {
                    'temperature': 0.1,  # Muy baja para mayor consistencia
                    'max_tokens': 800,
                    'response_format': 'json',
                    'stop': ['```', 'json', '**', '#'],  # Evitar formato markdown
                    'top_p': 0.9
                })
                
                if response.get('error'):
                    last_error = response['error']
                    logger.warning(f"‚ö†Ô∏è Ollama error attempt {attempt}: {response['error']}")
                    continue
                
                # Parsear respuesta JSON con m√∫ltiples estrategias
                response_text = response.get('response', '').strip()
                logger.info(f"üì• Ollama response attempt {attempt} for task {task_id}: {response_text[:200]}...")
                
                plan_data = None
                
                # Estrategia 1: JSON limpio directo
                try:
                    cleaned_response = response_text.replace('```json', '').replace('```', '').strip()
                    # Remover cualquier texto antes del primer {
                    if '{' in cleaned_response:
                        start_idx = cleaned_response.find('{')
                        cleaned_response = cleaned_response[start_idx:]
                    # Remover cualquier texto despu√©s del √∫ltimo }
                    if '}' in cleaned_response:
                        end_idx = cleaned_response.rfind('}') + 1
                        cleaned_response = cleaned_response[:end_idx]
                    
                    if cleaned_response.startswith('{') and cleaned_response.endswith('}'):
                        plan_data = json.loads(cleaned_response)
                except json.JSONDecodeError as e:
                    logger.debug(f"üìù JSON parsing strategy 1 failed: {str(e)}")
                
                # Estrategia 2: Buscar JSON en el texto (mejorado)
                if not plan_data:
                    try:
                        # Buscar patr√≥n JSON completo m√°s robusto
                        json_patterns = [
                            r'\{[^}]*"steps"[^}]*\[.*?\][^}]*\}',
                            r'\{.*?"steps".*?\[.*?\].*?\}',
                            r'(\{[^{}]*\{[^{}]*\}[^{}]*\})'
                        ]
                        
                        for pattern in json_patterns:
                            json_match = re.search(pattern, response_text, re.DOTALL)
                            if json_match:
                                plan_data = json.loads(json_match.group())
                                break
                    except json.JSONDecodeError as e:
                        logger.debug(f"üìù JSON parsing strategy 2 failed: {str(e)}")
                
                # Estrategia 3: JSON con correcci√≥n de formato com√∫n (mejorado)
                if not plan_data:
                    try:
                        # Limpiar markdown y texto extra
                        corrected_text = response_text
                        # Remover markdown
                        corrected_text = re.sub(r'\*\*.*?\*\*', '', corrected_text)
                        corrected_text = re.sub(r'\*.*?\*', '', corrected_text)
                        corrected_text = re.sub(r'#.*?\n', '', corrected_text)
                        # Corregir comillas simples por dobles
                        corrected_text = corrected_text.replace("'", '"')
                        # Buscar solo el JSON
                        if '{' in corrected_text and '}' in corrected_text:
                            start_idx = corrected_text.find('{')
                            end_idx = corrected_text.rfind('}') + 1
                            corrected_text = corrected_text[start_idx:end_idx]
                        
                        plan_data = json.loads(corrected_text)
                    except (json.JSONDecodeError, Exception) as e:
                        logger.debug(f"üìù JSON parsing strategy 3 failed: {str(e)}")
                
                # Estrategia 4: Crear JSON desde texto estructurado
                if not plan_data:
                    try:
                        # Si hay listas numeradas, convertir a JSON
                        if '1.' in response_text and ('2.' in response_text or '3.' in response_text):
                            steps = []
                            lines = response_text.split('\n')
                            current_step = None
                            
                            for line in lines:
                                line = line.strip()
                                if re.match(r'^\d+\.', line):
                                    if current_step:
                                        steps.append(current_step)
                                    title = re.sub(r'^\d+\.\s*\*\*?', '', line)
                                    title = re.sub(r'\*\*?:.*', '', title).strip()
                                    current_step = {
                                        'title': title,
                                        'description': f'Completar: {title}',
                                        'tool': 'processing',
                                        'estimated_time': '2-5 minutos',
                                        'priority': 'media'
                                    }
                                elif current_step and line:
                                    current_step['description'] = line
                            
                            if current_step:
                                steps.append(current_step)
                            
                            if len(steps) > 0:
                                plan_data = {
                                    'steps': steps,
                                    'task_type': 'an√°lisis_estructurado',
                                    'complexity': 'media',
                                    'estimated_total_time': f'{len(steps) * 3}-{len(steps) * 6} minutos'
                                }
                    except Exception as e:
                        logger.debug(f"üìù JSON parsing strategy 4 failed: {str(e)}")
                
                if not plan_data:
                    last_error = f"No se pudo parsear JSON v√°lido. Respuesta: {response_text[:100]}..."
                    logger.warning(f"‚ùå Failed to parse JSON on attempt {attempt}: {last_error}")
                    continue
                
                # Validar esquema
                if not validate_plan_schema(plan_data):
                    last_error = "El JSON no cumple con el esquema requerido"
                    logger.warning(f"‚ùå Schema validation failed on attempt {attempt}")
                    continue
                
                # Validar que el plan tenga la estructura esperada
                if not isinstance(plan_data.get('steps'), list) or len(plan_data.get('steps', [])) == 0:
                    last_error = "El plan no contiene pasos v√°lidos"
                    logger.warning(f"‚ùå Invalid plan structure on attempt {attempt}")
                    continue
                
                logger.info(f"‚úÖ Successfully generated and validated unified plan for task {task_id} on attempt {attempt}")
                return plan_data
                
            except Exception as e:
                last_error = f"Error inesperado: {str(e)}"
                logger.error(f"‚ùå Unexpected error on attempt {attempt} for task {task_id}: {str(e)}")
                continue
        
        # Si llegamos aqu√≠, todos los reintentos fallaron
        logger.error(f"‚ùå All {max_attempts} plan generation attempts failed for task {task_id}. Last error: {last_error}")
        
        # ESTRATEGIA DE EMERGENCIA: Crear plan b√°sico estructurado basado en an√°lisis del mensaje
        logger.warning(f"üÜò Activating emergency plan generation for task {task_id}")
        
        try:
            emergency_plan = generate_emergency_structured_plan(message, task_id, last_error)
            logger.info(f"‚úÖ Emergency plan generated successfully for task {task_id}")
            return emergency_plan
        except Exception as emergency_error:
            logger.error(f"‚ùå Emergency plan generation also failed for task {task_id}: {str(emergency_error)}")
            raise Exception(f"Complete failure: All plan generation strategies failed. Ollama errors: {last_error}. Emergency error: {str(emergency_error)}")
    
    try:
        # Intentar generar plan con reintentos
        plan_data = generate_plan_with_retries()
        
        # Convertir a formato frontend
        plan_steps = []
        for i, step in enumerate(plan_data.get('steps', [])):
            if not isinstance(step, dict):
                logger.warning(f"‚ö†Ô∏è Invalid step format for task {task_id}, step {i}: {step}")
                continue
                
            plan_steps.append({
                'id': f"step_{i+1}",
                'title': step.get('title', f'Paso {i+1}').strip(),
                'description': step.get('description', 'Procesando...').strip(),
                'tool': step.get('tool', 'processing'),
                'status': 'pending',
                'estimated_time': step.get('estimated_time', '1 minuto'),
                'completed': False,
                'active': i == 0,  # Solo el primer paso activo
                'priority': step.get('priority', 'media')
            })
        
        if len(plan_steps) == 0:
            logger.error(f"‚ùå No valid steps created for task {task_id}")
            return generate_fallback_plan_with_notification(message, task_id, "No se pudieron crear pasos v√°lidos")
            
        # Guardar plan con TaskManager (persistencia MongoDB)
        task_data = {
            'plan': plan_steps,
            'current_step': 0,
            'status': 'plan_generated',  # ‚úÖ MEJORA: Estado inicial correcto
            'created_at': datetime.now().isoformat(),
            'start_time': datetime.now(),
            'message': message,
            'task_type': plan_data.get('task_type', 'general'),
            'complexity': plan_data.get('complexity', 'media'),
            'ai_generated': True,
            'plan_source': 'unified_ai_generated'  # Indicar fuente del plan unificado
        }
        
        # Guardar en persistencia y memoria legacy
        save_task_data(task_id, task_data)
        
        logger.info(f"üéâ Generated unified AI-powered plan for task {task_id} with {len(plan_steps)} specific steps")
        logger.info(f"üìã Plan steps for task {task_id}: {[step['title'] for step in plan_steps]}")
        
        return {
            'steps': plan_steps,
            'total_steps': len(plan_steps),
            'estimated_total_time': plan_data.get('estimated_total_time', '2-5 minutos'),
            'task_type': plan_data.get('task_type', 'unified_ai_generated_dynamic'),
            'complexity': plan_data.get('complexity', 'media'),
            'ai_generated': True,
            'plan_source': 'unified_ai_generated',  # ‚úÖ MEJORA: Indicar fuente del plan unificado
            'schema_validated': True  # ‚úÖ MEJORA: Indicar que pas√≥ validaci√≥n
        }
            
    except Exception as e:
        logger.error(f"‚ùå All retries failed for unified AI plan generation task {task_id}: {str(e)}")
        return generate_fallback_plan_with_notification(message, task_id, f"Error en generaci√≥n IA unificada: {str(e)}")

def generate_dynamic_plan_with_ai(message: str, task_id: str) -> dict:
    """
    DEPRECATED: Usar generate_unified_ai_plan en su lugar
    Mantenido temporalmente para compatibilidad con c√≥digo existente
    """
    logger.warning(f"‚ö†Ô∏è Using deprecated generate_dynamic_plan_with_ai, consider migrating to generate_unified_ai_plan")
    return generate_unified_ai_plan(message, task_id, attempt_retries=True)

def generate_fallback_plan_with_notification(message: str, task_id: str, error_reason: str = None) -> dict:
    """
    Genera un plan de fallback con notificaci√≥n expl√≠cita al usuario
    Mejora implementada seg√∫n UPGRADE.md Secci√≥n 2: Manejo Expl√≠cito de Fallback
    """
    logger.warning(f"üîÑ Generating fallback plan for task {task_id} - Reason: {error_reason or 'AI not available'}")
    
    fallback_plan = generate_fallback_plan(message, task_id)
    
    # Agregar informaci√≥n de fallback
    fallback_plan['plan_source'] = 'fallback'
    fallback_plan['fallback_reason'] = error_reason or 'AI generation failed'
    fallback_plan['warning'] = 'Plan generado por contingencia - precisi√≥n limitada'
    
    # Marcar en memoria global que es fallback
    if task_id in active_task_plans:
        active_task_plans[task_id]['plan_source'] = 'fallback'
        active_task_plans[task_id]['fallback_reason'] = error_reason
        active_task_plans[task_id]['warning'] = 'Plan generado por contingencia'
    
    return fallback_plan

def generate_fallback_plan(message: str, task_id: str) -> dict:
    """
    Genera un plan de fallback m√°s espec√≠fico cuando la IA no est√° disponible
    """
    try:
        logger.warning(f"üîÑ Generating fallback plan for task {task_id} (AI not available)")
        
        # Analizar el mensaje para determinar el tipo de tarea con m√°s detalle
        message_lower = message.lower()
        original_message = message.strip()
        
        # Extraer palabras clave espec√≠ficas para personalizaci√≥n
        keywords = [word for word in message_lower.split() if len(word) > 3]
        
        # Patrones m√°s espec√≠ficos para diferentes tipos de tareas
        if any(word in message_lower for word in ['crear', 'generar', 'escribir', 'desarrollar', 'dise√±ar', 'construir', 'hacer', 'elaborar']):
            # Extraer el objeto de la creaci√≥n de forma m√°s inteligente
            task_subject = original_message
            for word in ['crear', 'generar', 'escribir', 'desarrollar', 'dise√±ar', 'construir', 'hacer', 'elaborar', 'un', 'una', 'el', 'la']:
                task_subject = task_subject.replace(word, '').replace(word.capitalize(), '')
            task_subject = task_subject.strip()
            
            if not task_subject:
                task_subject = "contenido solicitado"
            
            plan_steps = [
                {
                    'id': 'step_1',
                    'title': f'An√°lisis detallado: {task_subject}',
                    'description': f'Analizar requisitos espec√≠ficos, contexto y objetivos para {task_subject}',
                    'tool': 'analysis',
                    'status': 'pending',
                    'estimated_time': '45 segundos',
                    'completed': False,
                    'active': True
                },
                {
                    'id': 'step_2',
                    'title': f'Estructuraci√≥n y dise√±o',
                    'description': f'Definir estructura, formato y metodolog√≠a para {task_subject}',
                    'tool': 'planning',
                    'status': 'pending',
                    'estimated_time': '1 minuto',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_3',
                    'title': f'Desarrollo y creaci√≥n',
                    'description': f'Ejecutar la creaci√≥n completa de {task_subject} siguiendo los requisitos identificados',
                    'tool': 'creation',
                    'status': 'pending',
                    'estimated_time': '2-3 minutos',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_4',
                    'title': f'Revisi√≥n y optimizaci√≥n final',
                    'description': f'Revisar calidad, completitud y entregar {task_subject} finalizado',
                    'tool': 'delivery',
                    'status': 'pending',
                    'estimated_time': '30 segundos',
                    'completed': False,
                    'active': False
                }
            ]
            
        elif any(word in message_lower for word in ['buscar', 'investigar', 'analizar', 'estudiar', 'revisar', 'informaci√≥n', 'datos', 'investigaci√≥n']):
            # Extraer tema de investigaci√≥n de forma m√°s inteligente
            research_topic = original_message
            for word in ['buscar', 'investigar', 'analizar', 'estudiar', 'revisar', 'informaci√≥n', 'sobre', 'acerca', 'de', 'datos', 'dame', 'necesito']:
                research_topic = research_topic.replace(word, '').replace(word.capitalize(), '')
            research_topic = research_topic.strip()
            
            if not research_topic:
                research_topic = "tema solicitado"
                
            plan_steps = [
                {
                    'id': 'step_1',
                    'title': f'Estrategia de investigaci√≥n: {research_topic}',
                    'description': f'Definir metodolog√≠a, fuentes y alcance de investigaci√≥n para {research_topic}',
                    'tool': 'search_definition',
                    'status': 'pending',
                    'estimated_time': '30 segundos',
                    'completed': False,
                    'active': True
                },
                {
                    'id': 'step_2',
                    'title': f'Recopilaci√≥n de informaci√≥n especializada',
                    'description': f'Buscar informaci√≥n actualizada y relevante sobre {research_topic} en m√∫ltiples fuentes',
                    'tool': 'web_search',
                    'status': 'pending',
                    'estimated_time': '1-2 minutos',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_3',
                    'title': f'An√°lisis y procesamiento de datos',
                    'description': f'Analizar, filtrar y procesar la informaci√≥n recopilada sobre {research_topic}',
                    'tool': 'data_analysis',
                    'status': 'pending',
                    'estimated_time': '1 minuto',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_4',
                    'title': f'S√≠ntesis y presentaci√≥n de hallazgos',
                    'description': f'Sintetizar resultados y presentar conclusiones sobre {research_topic}',
                    'tool': 'synthesis',
                    'status': 'pending',
                    'estimated_time': '45 segundos',
                    'completed': False,
                    'active': False
                }
            ]
            
        elif any(word in message_lower for word in ['explica', 'define', 'qu√© es', 'c√≥mo', 'por qu√©', 'cu√°l']):
            # Preguntas explicativas
            topic = original_message.replace('?', '').strip()
            
            plan_steps = [
                {
                    'id': 'step_1',
                    'title': f'Investigaci√≥n conceptual: {topic}',
                    'description': f'Buscar definiciones, conceptos clave y contexto para responder: {topic}',
                    'tool': 'web_search',
                    'status': 'pending',
                    'estimated_time': '1 minuto',
                    'completed': False,
                    'active': True
                },
                {
                    'id': 'step_2',
                    'title': f'An√°lisis y estructuraci√≥n',
                    'description': f'Analizar informaci√≥n encontrada y estructurar respuesta comprensible',
                    'tool': 'analysis',
                    'status': 'pending',
                    'estimated_time': '45 segundos',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_3',
                    'title': f'Formulaci√≥n de respuesta completa',
                    'description': f'Crear respuesta detallada y educativa para: {topic}',
                    'tool': 'synthesis',
                    'status': 'pending',
                    'estimated_time': '30 segundos',
                    'completed': False,
                    'active': False
                }
            ]
            
        else:
            # Plan adaptativo para tareas no clasificadas
            plan_steps = [
                {
                    'id': 'step_1',
                    'title': f'Interpretaci√≥n de solicitud: "{original_message[:30]}..."',
                    'description': f'Analizar y comprender los requisitos espec√≠ficos de: {original_message}',
                    'tool': 'analysis',
                    'status': 'pending',
                    'estimated_time': '30 segundos',
                    'completed': False,
                    'active': True
                },
                {
                    'id': 'step_2',
                    'title': f'Planificaci√≥n de ejecuci√≥n',
                    'description': f'Definir metodolog√≠a y pasos para cumplir con: {original_message}',
                    'tool': 'planning',
                    'status': 'pending',
                    'estimated_time': '45 segundos',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_3',
                    'title': f'Procesamiento y ejecuci√≥n',
                    'description': f'Ejecutar y procesar seg√∫n los requisitos identificados',
                    'tool': 'processing',
                    'status': 'pending',
                    'estimated_time': '1-2 minutos',
                    'completed': False,
                    'active': False
                },
                {
                    'id': 'step_4',
                    'title': f'Entrega de resultados finales',
                    'description': f'Entregar resultado completo que satisfaga: {original_message}',
                    'tool': 'delivery',
                    'status': 'pending',
                    'estimated_time': '30 segundos',
                    'completed': False,
                    'active': False
                }
            ]
        
        # Guardar plan en memoria global con timestamp
        active_task_plans[task_id] = {
            'plan': plan_steps,
            'current_step': 0,
            'status': 'executing',
            'created_at': datetime.now().isoformat(),
            'start_time': datetime.now(),
            'message': message,
            'ai_generated': False  # Marcar como plan de fallback
        }
        
        logger.info(f"üìã Generated fallback plan for task {task_id} with {len(plan_steps)} customized steps")
        
        return {
            'steps': plan_steps,
            'total_steps': len(plan_steps),
            'estimated_total_time': '2-4 minutos',
            'task_type': 'adaptive_fallback_plan',
            'ai_generated': False
        }
        
    except Exception as e:
        logger.error(f"Error generating structured plan: {str(e)}")
        # Plan de fallback simple
        fallback_plan = [
            {
                'id': 'step_1',
                'title': 'Procesando solicitud',
                'description': 'Procesando tu solicitud...',
                'tool': 'processing',
                'status': 'pending',
                'estimated_time': '1 minuto',
                'completed': False,
                'active': True
            }
        ]
        
        active_task_plans[task_id] = {
            'plan': fallback_plan,
            'current_step': 0,
            'status': 'executing',
            'created_at': datetime.now().isoformat(),
            'message': message
        }
        
        return {
            'steps': fallback_plan,
            'total_steps': 1,
            'estimated_total_time': '1 minuto',
            'task_type': 'simple_execution'
        }



def generate_clean_response(ollama_response: str, tool_results: list, task_status: str = "success", 
                          failed_step_title: str = None, error_message: str = None, warnings: list = None) -> dict:
    """
    Genera una respuesta final estructurada en JSON basada en el estado real de la tarea
    ENHANCED VERSION - As per NEWUPGRADE.md Section 4: Returns structured JSON instead of plain text
    
    Args:
        ollama_response: Respuesta original de Ollama
        tool_results: Resultados de herramientas ejecutadas
        task_status: Estado final de la tarea ('completed_success', 'completed_with_warnings', 'failed')
        failed_step_title: T√≠tulo del paso que fall√≥ (si aplica)
        error_message: Mensaje de error espec√≠fico (si aplica)
        warnings: Lista de advertencias detalladas (si aplica)
    
    Returns:
        dict: Objeto JSON estructurado con toda la informaci√≥n de la tarea
    """
    try:
        # Detectar archivos creados en los resultados
        files_created = []
        deliverables_info = []
        
        for result in tool_results or []:
            if isinstance(result, dict):
                if result.get('file_created') and result.get('file_name'):
                    files_created.append({
                        'name': result['file_name'],
                        'size': result.get('file_size', 0),
                        'download_url': result.get('download_url', ''),
                        'type': result.get('type', 'unknown')
                    })
                    
                if result.get('tangible_result') or result.get('final_deliverable'):
                    deliverables_info.append(result)
        
        # BUILD STRUCTURED RESPONSE OBJECT
        response_data = {
            "status": task_status,
            "message": "",  # Will be set below based on status
            "files_generated": files_created,
            "warnings": warnings or [],
            "error": error_message,
            "deliverables_count": len(files_created),
            "raw_ollama_response": ollama_response,
            "tool_results_count": len(tool_results or []),
            "timestamp": datetime.now().isoformat()
        }
        
        # Generate message based on task status
        if task_status == "completed_success":
            # Tarea completada exitosamente
            if files_created:
                response_data["message"] = f"""üéâ ¬°Excelente! He completado tu solicitud con √©xito y he generado {len(files_created)} archivo(s) tangible(s).

üìÅ **ARCHIVOS GENERADOS:**

"""
                for file_info in files_created:
                    response_data["message"] += f"""‚Ä¢ **{file_info['name']}** 
  üìÑ Tama√±o: {file_info.get('size', 0)} bytes
  üîó [Descargar archivo]({file_info.get('download_url', '#')})

"""
                response_data["message"] += """

‚úÖ **Estado**: Completado exitosamente
üìä **Resultados**: Todos los objetivos alcanzados

Puedes descargar los archivos haciendo clic en los enlaces de arriba."""
            else:
                response_data["message"] = f"""üéâ ¬°Perfecto! He completado tu solicitud exitosamente.

‚úÖ **Estado**: Completado con √©xito
üìã **Resumen**: {ollama_response[:200]}...

Todos los objetivos han sido alcanzados seg√∫n lo solicitado."""

        elif task_status == "completed_with_warnings":
            # Tarea completada pero con advertencias
            response_data["message"] = f"""‚ö†Ô∏è Tu solicitud ha sido completada, pero con algunas advertencias importantes.

üìã **Resumen**: {ollama_response[:200] if ollama_response else 'Tarea procesada'}...

‚ö†Ô∏è **ADVERTENCIAS DETECTADAS:**

"""
            for warning in (warnings or []):
                response_data["message"] += f"‚Ä¢ {warning}\n"

            if files_created:
                response_data["message"] += f"""

üìÅ **ARCHIVOS GENERADOS** ({len(files_created)}):

"""
                for file_info in files_created:
                    response_data["message"] += f"""‚Ä¢ **{file_info['name']}** 
  üîó [Descargar]({file_info.get('download_url', '#')})

"""
            response_data["message"] += """

‚úÖ **Estado**: Completado con advertencias
üí° **Recomendaci√≥n**: Revisa las advertencias antes de proceder."""

        elif task_status == "failed":
            # Tarea fallida
            response_data["message"] = f"""‚ùå Lo siento, no pude completar tu solicitud debido a un error.

üö® **ERROR PRINCIPAL**: {error_message or 'Error desconocido'}

"""
            if failed_step_title:
                response_data["message"] += f"üìç **Paso fallido**: {failed_step_title}\n\n"

            response_data["message"] += f"""üìã **Contexto**: {ollama_response[:150] if ollama_response else 'Sin contexto disponible'}...

‚ùå **Estado**: Fallido
üîß **Sugerencia**: Intenta reformular tu solicitud o contacta soporte t√©cnico."""

        else:
            # Estado desconocido - fallback
            response_data["message"] = f"""‚ÑπÔ∏è Tu solicitud ha sido procesada.

üìã **Informaci√≥n**: {ollama_response[:200] if ollama_response else 'Procesado'}...

üìä **Estado**: {task_status}
‚è∞ **Procesado**: {datetime.now().strftime('%d/%m/%Y %H:%M')}"""

        return response_data
        
    except Exception as e:
        logger.error(f"‚ùå Error generating clean response: {e}")
        # Return error response structure
        return {
            "status": "error",
            "message": f"‚ùå Error al generar respuesta final: {str(e)}",
            "files_generated": [],
            "warnings": ["Error interno al procesar respuesta"],
            "error": str(e),
            "deliverables_count": 0,
            "raw_ollama_response": ollama_response or "",
            "tool_results_count": len(tool_results or []),
            "timestamp": datetime.now().isoformat()
        }


def generate_clean_response_legacy(ollama_response: str, tool_results: list, task_status: str = "success", 
                          failed_step_title: str = None, error_message: str = None, warnings: list = None) -> str:
    """
    Genera una respuesta final condicional y din√°mica basada en el estado real de la tarea
    PROBLEMA 2: Incluye informaci√≥n sobre validaci√≥n de resultados y advertencias.
    
    Args:
        ollama_response: Respuesta original de Ollama
        tool_results: Resultados de herramientas ejecutadas
        task_status: Estado final de la tarea ('completed_success', 'completed_with_warnings', 'failed')
        failed_step_title: T√≠tulo del paso que fall√≥ (si aplica)
        error_message: Mensaje de error espec√≠fico (si aplica)
        warnings: Lista de advertencias detalladas (si aplica)
    
    Returns:
        str: Respuesta final apropiada para el estado de la tarea con informaci√≥n de archivos y validaci√≥n
    """
    try:
        # Detectar archivos creados en los resultados
        files_created = []
        deliverables_info = []
        
        for result in tool_results or []:
            if isinstance(result, dict):
                if result.get('file_created') and result.get('file_name'):
                    files_created.append({
                        'name': result['file_name'],
                        'size': result.get('file_size', 0),
                        'download_url': result.get('download_url', ''),
                        'type': result.get('type', 'unknown')
                    })
                    
                if result.get('tangible_result') or result.get('final_deliverable'):
                    deliverables_info.append(result)
        
        # Respuesta basada en el estado real de la tarea
        if task_status == "completed_success":
            # Tarea completada exitosamente
            if files_created:
                clean_response = f"""üéâ ¬°Excelente! He completado tu solicitud con √©xito y he generado {len(files_created)} archivo(s) tangible(s).

üìÅ **ARCHIVOS GENERADOS:**
"""
                for file_info in files_created:
                    clean_response += f"‚Ä¢ **{file_info['name']}** ({file_info['size']} bytes) - Listo para descargar\n"
                
                clean_response += """
‚úÖ He ejecutado todos los pasos del plan de acci√≥n que puedes ver en el panel lateral. La tarea se ha finalizado correctamente y todos los objetivos han sido alcanzados.

üîÑ **C√≥mo acceder a tus archivos:**
- Revisa el panel de progreso para enlaces de descarga
- Los archivos est√°n disponibles inmediatamente
- Puedes descargar cada archivo individualmente

üìä Puedes revisar los detalles completos de la ejecuci√≥n en el monitor de progreso."""
            else:
                clean_response = """¬°Excelente! He completado tu solicitud con √©xito. 

He ejecutado todos los pasos del plan de acci√≥n que puedes ver en el panel lateral. La tarea se ha finalizado correctamente y todos los objetivos han sido alcanzados.

Puedes revisar los detalles completos de la ejecuci√≥n en el monitor de progreso."""

        elif task_status == "plan_ready":
            # Plan generated and ready for execution - call Ollama for real response
            clean_response = ollama_response
            
        elif task_status == "completed_with_warnings":
            # üÜï PROBLEMA 2: Tarea completada con advertencias espec√≠ficas de validaci√≥n
            if files_created:
                clean_response = f"""‚úÖ He completado tu solicitud con {len(files_created)} archivo(s) generado(s), aunque con algunas advertencias menores.

üìÅ **ARCHIVOS GENERADOS:**
"""
                for file_info in files_created:
                    clean_response += f"‚Ä¢ **{file_info['name']}** ({file_info['size']} bytes)\n"
                
                clean_response += """
‚ö†Ô∏è El plan de acci√≥n se ejecut√≥ correctamente en general, pero algunos pasos tuvieron limitaciones."""
                
                # A√±adir advertencias espec√≠ficas si est√°n disponibles
                if warnings:
                    clean_response += f"""

**ADVERTENCIAS ESPEC√çFICAS:**
"""
                    for warning in warnings[:3]:  # Mostrar m√°ximo 3 advertencias
                        clean_response += f"‚Ä¢ {warning}\n"
                    
                    if len(warnings) > 3:
                        clean_response += f"‚Ä¢ ... y {len(warnings) - 3} advertencia(s) adicional(es)\n"
                
                clean_response += """

El resultado principal fue alcanzado exitosamente. Te recomiendo revisar el monitor de ejecuci√≥n para m√°s detalles."""
            else:
                clean_response = """He completado tu solicitud, aunque con algunas advertencias menores.

‚ö†Ô∏è El plan de acci√≥n se ejecut√≥ correctamente en general, pero algunos pasos tuvieron limitaciones."""
                
                # A√±adir advertencias espec√≠ficas si est√°n disponibles
                if warnings:
                    clean_response += f"""

**ADVERTENCIAS ESPEC√çFICAS:**
"""
                    for warning in warnings[:3]:  # Mostrar m√°ximo 3 advertencias
                        clean_response += f"‚Ä¢ {warning}\n"
                    
                    if len(warnings) > 3:
                        clean_response += f"‚Ä¢ ... y {len(warnings) - 3} advertencia(s) adicional(es)\n"
                
                clean_response += """

El resultado principal fue alcanzado exitosamente. Te recomiendo revisar el monitor de ejecuci√≥n para m√°s detalles."""

        elif task_status == "failed":
            # Tarea fall√≥
            failed_step_info = f" en el paso '{failed_step_title}'" if failed_step_title else ""
            error_info = f": {error_message}" if error_message else ""
            
            if files_created:
                clean_response = f"""‚ùå Lo siento, no pude completar totalmente tu solicitud debido a un error{failed_step_info}{error_info}.

Sin embargo, logr√© generar {len(files_created)} archivo(s) parcial(es):

üìÅ **ARCHIVOS PARCIALES GENERADOS:**
"""
                for file_info in files_created:
                    clean_response += f"‚Ä¢ **{file_info['name']}** ({file_info['size']} bytes)\n"
                
                clean_response += """
üîÑ He intentado ejecutar el plan de acci√≥n completo, pero encontr√© dificultades t√©cnicas. Los archivos parciales pueden contener informaci√≥n √∫til.

Por favor, revisa el monitor de ejecuci√≥n para m√°s detalles sobre el problema, o intenta reformular tu solicitud de manera diferente."""
            else:
                clean_response = f"""Lo siento, no pude completar tu solicitud debido a un error{failed_step_info}{error_info}.

He intentado ejecutar el plan de acci√≥n que puedes ver en el panel lateral, pero encontr√© dificultades t√©cnicas que impidieron la finalizaci√≥n.

Por favor, revisa el monitor de ejecuci√≥n para m√°s detalles sobre el problema, o intenta reformular tu solicitud de manera diferente."""

        else:
            # Estado por defecto (en progreso o desconocido)
            clean_response = """¬°Perfecto! He recibido tu solicitud y he preparado un plan de acci√≥n detallado.

üìã **Plan generado y listo para ejecutar**

El plan est√° listo para ejecutarse paso a paso. Puedes ver todos los pasos en el panel lateral y ejecutarlos uno por uno para un control total sobre el proceso.

üéØ **C√≥mo proceder:**
- Revisa el plan completo en el panel lateral
- Ejecuta cada paso cuando est√©s listo (los pasos deben completarse en orden)
- Supervisa los resultados de cada paso
- Los archivos generados aparecer√°n autom√°ticamente

‚ö° **Control total:** Tienes control completo sobre cu√°ndo y c√≥mo se ejecuta cada paso del plan."""

        # Agregar informaci√≥n sobre herramientas si est√°n disponibles
        if tool_results and task_status in ["completed_success", "completed_with_warnings"]:
            tools_summary = []
            successful_tools = 0
            failed_tools = 0
            
            for result in tool_results:
                if result.get('error'):
                    failed_tools += 1
                else:
                    successful_tools += 1
                    # Agregar informaci√≥n √∫til del resultado si est√° disponible
                    if isinstance(result.get('result'), dict):
                        if 'output' in result['result']:
                            tools_summary.append(f"‚úÖ {result['tool']}: Completado exitosamente")
            
            # Agregar resumen de herramientas al final
            if successful_tools > 0 or failed_tools > 0:
                clean_response += f"\n\n---\n**üîß Resumen de Ejecuci√≥n:** {successful_tools} herramientas exitosas"
                if failed_tools > 0:
                    clean_response += f", {failed_tools} con errores"
                if files_created:
                    clean_response += f", {len(files_created)} archivo(s) generado(s)"
                clean_response += "\n"
                
                # Agregar detalles de herramientas exitosas (m√°ximo 3)
                for summary in tools_summary[:3]:
                    clean_response += f"{summary}\n"
        
        elif tool_results and task_status == "failed":
            # Para tareas fallidas, mostrar qu√© herramientas se intentaron
            attempted_tools = [result.get('tool', 'Desconocida') for result in tool_results]
            if attempted_tools:
                clean_response += f"\n\n**üîß Herramientas intentadas:** {', '.join(attempted_tools[:3])}"
        
        return clean_response
        
    except Exception as e:
        logger.error(f"‚ùå Error generating conditional clean response: {str(e)}")
        # Fallback seguro con informaci√≥n del error
        fallback_response = """He recibido tu solicitud y estoy trabajando en ella. 

Puedes ver el progreso del plan de acci√≥n en el panel lateral derecho. El plan se ejecutar√° autom√°ticamente paso a paso."""
        
        if task_status == "failed" and error_message:
            fallback_response += f"\n\n‚ö†Ô∏è Nota: Se encontr√≥ un problema t√©cnico - {error_message}"
        
        return fallback_response

@agent_bp.route('/chat', methods=['POST'])
def chat():
    """
    Endpoint principal del chat - VERSI√ìN REAL CON OLLAMA
    Distingue entre conversaciones casuales y tareas complejas
    GENERA PLAN ESTRUCTURADO PARA MOSTRAR EN PLAN DE ACCI√ìN
    """
    try:
        data = request.get_json()
        message = data.get('message', '')
        context = data.get('context', {})
        
        if not message:
            return jsonify({'error': 'Message is required'}), 400
        
        # Obtener task_id del contexto
        task_id = context.get('task_id', str(uuid.uuid4()))
        
        logger.info(f"üöÄ Processing message: {message[:50]}... (ID: {task_id})")
        
        # Obtener servicio de Ollama
        ollama_service = get_ollama_service()
        if not ollama_service:
            return jsonify({
                'error': 'Ollama service not available',
                'response': 'Lo siento, el servicio de IA no est√° disponible en este momento.'
            }), 503
        
        # PASO 1: Detectar si es conversaci√≥n casual o tarea compleja
        is_casual = is_casual_conversation(message)
        
        if is_casual:
            # MODO CONVERSACI√ìN CASUAL
            logger.info(f"üó£Ô∏è Detected casual conversation mode")
            
            # Usar solo Ollama para respuesta casual
            ollama_response = ollama_service.generate_casual_response(message, context)
            
            if ollama_response.get('error'):
                return jsonify({
                    'error': ollama_response['error'],
                    'response': ollama_response['response']
                }), 500
            
            return jsonify({
                'response': ollama_response['response'],
                'task_id': task_id,
                'timestamp': datetime.now().isoformat(),
                'execution_status': 'completed',
                'mode': 'casual_conversation',
                'memory_used': True
            })
        
        else:
            # MODO AGENTE CON PLANIFICACI√ìN ESTRUCTURADA
            logger.info(f"ü§ñ Detected task mode - generating structured plan")
            
            # PASO 2: Generar plan din√°mico PRIMERO usando IA
            structured_plan = generate_dynamic_plan_with_ai(message, task_id)
            
            # ‚ú® NUEVA FUNCIONALIDAD: Generar t√≠tulo mejorado con LLM
            enhanced_title = generate_task_title_with_llm(message, task_id)
            logger.info(f"üìù Enhanced title generated alongside plan: '{enhanced_title}'")
            
            # PASO 3: Generar respuesta usando Ollama con contexto de herramientas
            ollama_response = ollama_service.generate_response(message, context, use_tools=True)
            
            if ollama_response.get('error'):
                return jsonify({
                    'error': ollama_response['error'],
                    'response': ollama_response['response']
                }), 500
            
            # PASO 4: Procesar tool_calls si existen
            tool_results = []
            if ollama_response.get('tool_calls'):
                logger.info(f"üîß Processing {len(ollama_response['tool_calls'])} tool calls")
                tool_manager = get_tool_manager()
                
                if tool_manager:
                    for tool_call in ollama_response['tool_calls']:
                        try:
                            tool_name = tool_call.get('tool')
                            parameters = tool_call.get('parameters', {})
                            
                            logger.info(f"üîß Executing tool: {tool_name}")
                            
                            # Ejecutar herramienta real
                            tool_result = tool_manager.execute_tool(tool_name, parameters)
                            tool_results.append({
                                'tool': tool_name,
                                'parameters': parameters,
                                'result': tool_result
                            })
                            
                        except Exception as e:
                            logger.error(f"Error executing tool {tool_name}: {str(e)}")
                            tool_results.append({
                                'tool': tool_name,
                                'parameters': parameters,
                                'error': str(e)
                            })
            
            # PASO 5: Generar respuesta LIMPIA basada en estado inicial (tarea comenzando)
            final_response = generate_clean_response(ollama_response['response'], tool_results, 
                                                    task_status="plan_ready", 
                                                    failed_step_title=None, 
                                                    error_message=None)
            
            # MODIFICACI√ìN: NO ejecutar autom√°ticamente - dejar que el usuario controle la ejecuci√≥n paso a paso
            # execute_plan_with_real_tools(task_id, structured_plan['steps'], message)
            
            logger.info(f"‚úÖ Plan generated successfully - ready for step-by-step execution")
            
            # üöÄ Emitir evento WebSocket de plan actualizado
            websocket_manager = getattr(current_app, 'websocket_manager', None)
            if websocket_manager and hasattr(websocket_manager, 'emit_update') and structured_plan and 'steps' in structured_plan:
                from src.websocket.websocket_manager import UpdateType
                websocket_manager.emit_update(
                    task_id=task_id,
                    update_type=UpdateType.PLAN_UPDATED,
                    data={
                        'plan': structured_plan,
                        'task_id': task_id,
                        'auto_execute': True,  # Activar ejecuci√≥n autom√°tica
                        'timestamp': datetime.now().isoformat()
                    }
                )
                logger.info(f"üì° Plan emitted via WebSocket for task {task_id}")
            else:
                logger.warning(f"‚ö†Ô∏è WebSocket manager not available for task {task_id}")
            
            # üéØ INICIAR EJECUCI√ìN AUTOM√ÅTICA DESPU√âS DE GENERAR EL PLAN
            logger.info(f"üöÄ Starting automatic execution for task {task_id}")
            try:
                # Llamar internamente al endpoint de ejecuci√≥n autom√°tica
                import threading
                app = current_app._get_current_object()
                
                def auto_execute_with_context():
                    with app.app_context():
                        logger.info(f"üîÑ Auto-executing task {task_id} with {len(structured_plan.get('steps', []))} steps")
                        execute_task_steps_sequentially(task_id, structured_plan.get('steps', []))
                        logger.info(f"‚úÖ Auto-execution completed for task {task_id}")
                
                execution_thread = threading.Thread(target=auto_execute_with_context)
                execution_thread.daemon = True
                execution_thread.start()
                
                logger.info(f"üéØ Auto-execution thread started for task {task_id}")
                execution_status = 'executing'  # Estado: ejecut√°ndose autom√°ticamente
                
            except Exception as e:
                logger.error(f"‚ùå Error starting auto-execution for task {task_id}: {e}")
                execution_status = 'plan_ready'  # Fallback al estado anterior
            
            return jsonify({
                'response': final_response,
                'task_id': task_id,
                'plan': structured_plan,  # PLAN ESTRUCTURADO PARA FRONTEND
                'enhanced_title': enhanced_title,  # ‚ú® NUEVO: T√≠tulo mejorado generado con LLM
                'tool_calls': ollama_response.get('tool_calls', []),
                'tool_results': tool_results,
                'timestamp': datetime.now().isoformat(),
                'execution_status': execution_status,  # Estado din√°mico: executing o plan_ready
                'mode': 'agent_with_structured_plan',
                'memory_used': True
            })
    
    except Exception as e:
        logger.error(f"Error general en chat: {str(e)}")
        return jsonify({
            'error': f'Error interno del servidor: {str(e)}',
            'response': 'Lo siento, hubo un error procesando tu solicitud.'
        }), 500

@agent_bp.route('/test-plan-generation', methods=['POST'])
def test_plan_generation():
    """
    Endpoint para probar la generaci√≥n de planes con IA
    """
    try:
        data = request.get_json() or {}
        message = data.get('message', 'Crear un informe completo sobre inteligencia artificial en 2024')
        task_id = data.get('task_id', f'test-{uuid.uuid4()}')
        
        logger.info(f"üß™ Testing AI plan generation for: {message}")
        
        # Probar generaci√≥n con IA
        ai_plan = generate_dynamic_plan_with_ai(message, task_id)
        
        # Tambi√©n generar plan de fallback para comparaci√≥n
        fallback_task_id = f'fallback-{uuid.uuid4()}'
        fallback_plan = generate_fallback_plan(message, fallback_task_id)
        
        return jsonify({
            'test_results': {
                'ai_plan': {
                    'plan': ai_plan,
                    'ai_generated': ai_plan.get('ai_generated', False),
                    'plan_type': ai_plan.get('task_type', 'unknown')
                },
                'fallback_plan': {
                    'plan': fallback_plan,
                    'ai_generated': fallback_plan.get('ai_generated', False),
                    'plan_type': fallback_plan.get('task_type', 'unknown')
                }
            },
            'test_message': message,
            'timestamp': datetime.now().isoformat(),
            'comparison': {
                'ai_steps': len(ai_plan.get('steps', [])),
                'fallback_steps': len(fallback_plan.get('steps', [])),
                'ai_working': len(ai_plan.get('steps', [])) > 0,
                'plans_different': ai_plan.get('steps', []) != fallback_plan.get('steps', [])
            }
        })
    
    except Exception as e:
        logger.error(f"‚ùå Error in plan generation test: {str(e)}")
        return jsonify({
            'error': f'Error testing plan generation: {str(e)}',
            'test_failed': True
        }), 500

@agent_bp.route('/download/<filename>', methods=['GET'])
def download_file(filename):
    """
    Endpoint para descargar archivos generados por el agente
    """
    try:
        import os
        from flask import send_file, abort
        
        # Validar nombre de archivo para seguridad
        if not filename or '..' in filename or '/' in filename:
            abort(400, "Invalid filename")
        
        file_path = f"/app/backend/static/generated_files/{filename}"
        
        # Verificar que el archivo existe
        if not os.path.exists(file_path):
            abort(404, "File not found")
        
        logger.info(f"üì• Downloading file: {filename}")
        
        # Determinar tipo MIME
        import mimetypes
        mimetype = mimetypes.guess_type(filename)[0]
        if not mimetype:
            if filename.endswith('.md'):
                mimetype = 'text/markdown'
            elif filename.endswith('.txt'):
                mimetype = 'text/plain'
            elif filename.endswith('.py'):
                mimetype = 'text/x-python'
            else:
                mimetype = 'application/octet-stream'
        
        return send_file(
            file_path, 
            as_attachment=True, 
            download_name=filename,
            mimetype=mimetype
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error downloading file {filename}: {str(e)}")
        return jsonify({'error': f'Error downloading file: {str(e)}'}), 500

@agent_bp.route('/list-files', methods=['GET'])
def list_generated_files():
    """
    Endpoint para listar archivos generados por el agente
    """
    try:
        import os
        from datetime import datetime
        
        files_dir = "/app/backend/static/generated_files"
        
        if not os.path.exists(files_dir):
            return jsonify({'files': []})
        
        files = []
        for filename in os.listdir(files_dir):
            file_path = os.path.join(files_dir, filename)
            if os.path.isfile(file_path):
                stat = os.stat(file_path)
                files.append({
                    'name': filename,
                    'size': stat.st_size,
                    'created': datetime.fromtimestamp(stat.st_ctime).isoformat(),
                    'modified': datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    'download_url': f'/api/agent/download/{filename}'
                })
        
        # Ordenar por fecha de creaci√≥n (m√°s reciente primero)
        files.sort(key=lambda x: x['created'], reverse=True)
        
        return jsonify({
            'files': files,
            'total_files': len(files),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error listing files: {str(e)}")
        return jsonify({'error': f'Error listing files: {str(e)}'}), 500

@agent_bp.route('/generate-plan', methods=['POST'])
def generate_plan():
    """
    Genera un plan de acci√≥n din√°mico usando IA mejorada
    """
    try:
        data = request.get_json() or {}
        task_title = data.get('task_title', '')
        task_id = data.get('task_id', str(uuid.uuid4()))
        
        if not task_title:
            return jsonify({'error': 'task_title is required'}), 400
        
        logger.info(f"üöÄ Generating dynamic plan for: {task_title}")
        
        # Usar la nueva funci√≥n de generaci√≥n din√°mica con IA
        dynamic_plan = generate_dynamic_plan_with_ai(task_title, task_id)
        
        logger.info(f"‚úÖ Dynamic plan generated with {len(dynamic_plan['steps'])} steps")
        
        return jsonify({
            'plan': dynamic_plan['steps'],
            'task_id': task_id,
            'total_steps': dynamic_plan['total_steps'],
            'estimated_total_time': dynamic_plan['estimated_total_time'],
            'task_type': dynamic_plan['task_type'],
            'complexity': dynamic_plan.get('complexity', 'media'),
            'timestamp': datetime.now().isoformat(),
            'status': 'plan_generated',
            'ai_generated': dynamic_plan.get('ai_generated', False)
        })
    
    except Exception as e:
        logger.error(f"Error generating dynamic plan: {str(e)}")
        return jsonify({
            'error': f'Error generando plan: {str(e)}'
        }), 500

@agent_bp.route('/update-task-progress', methods=['POST'])
def update_task_progress():
    """Actualiza el progreso de una tarea"""
    try:
        data = request.get_json() or {}
        task_id = data.get('task_id', '')
        step_id = data.get('step_id', '')
        completed = data.get('completed', False)
        
        if not task_id or not step_id:
            return jsonify({'error': 'task_id and step_id are required'}), 400
        
        # Actualizar progreso en memoria
        if task_id in active_task_plans:
            plan = active_task_plans[task_id]['plan']
            for step in plan:
                if step['id'] == step_id:
                    step['completed'] = completed
                    step['status'] = 'completed' if completed else 'pending'
                    break
            
            # Actualizar plan en memoria
            active_task_plans[task_id]['plan'] = plan
        
        return jsonify({
            'success': True,
            'task_id': task_id,
            'step_id': step_id,
            'completed': completed
        })
        
    except Exception as e:
        logger.error(f"Error updating task progress: {str(e)}")
        return jsonify({
            'error': f'Error actualizando progreso: {str(e)}'
        }), 500

@agent_bp.route('/update-task-time/<task_id>', methods=['POST'])
def update_task_time(task_id):
    """Actualiza el tiempo transcurrido de una tarea en tiempo real"""
    try:
        if task_id in active_task_plans:
            plan_data = active_task_plans[task_id]
            start_time = plan_data.get('start_time')
            
            if start_time:
                # Calcular tiempo transcurrido
                elapsed = datetime.now() - start_time
                elapsed_seconds = int(elapsed.total_seconds())
                
                # Formatear tiempo como MM:SS
                minutes = elapsed_seconds // 60
                seconds = elapsed_seconds % 60
                elapsed_str = f"{minutes}:{seconds:02d}"
                
                # Actualizar el paso activo
                plan = plan_data['plan']
                for step in plan:
                    if step.get('active', False):
                        step['elapsed_time'] = f"{elapsed_str} Pensando"
                        break
                
                # Actualizar en memoria
                active_task_plans[task_id]['plan'] = plan
                
                return jsonify({
                    'success': True,
                    'elapsed_time': elapsed_str,
                    'plan': plan
                })
            
        return jsonify({'error': 'Task not found'}), 404
        
    except Exception as e:
        logger.error(f"Error updating task time: {str(e)}")
        return jsonify({'error': str(e)}), 500



@agent_bp.route('/get-final-result/<task_id>', methods=['GET'])
def get_final_result(task_id):
    """Obtiene el resultado final de una tarea completada"""
    try:
        if task_id in active_task_plans:
            plan_data = active_task_plans[task_id]
            
            if plan_data['status'] == 'completed' and 'final_result' in plan_data:
                return jsonify({
                    'task_id': task_id,
                    'status': 'completed',
                    'final_result': plan_data['final_result'],
                    'plan_summary': {
                        'total_steps': len(plan_data['plan']),
                        'completed_steps': sum(1 for step in plan_data['plan'] if step['completed']),
                        'task_type': plan_data.get('task_type', 'general'),
                        'complexity': plan_data.get('complexity', 'media')
                    }
                })
            else:
                return jsonify({
                    'task_id': task_id,
                    'status': plan_data['status'],
                    'message': 'Tarea a√∫n no completada o sin resultado final'
                })
        else:
            return jsonify({
                'error': 'Task not found'
            }), 404
    
    except Exception as e:
        logger.error(f"Error getting final result: {str(e)}")
        return jsonify({
            'error': f'Error obteniendo resultado final: {str(e)}'
        }), 500

@agent_bp.route("/model-info", methods=["GET"])
def get_model_info():
    """
    PROBLEMA 3: Endpoint para obtener informaci√≥n de configuraci√≥n de modelos
    """
    try:
        ollama_service = get_ollama_service()
        if not ollama_service:
            return jsonify({
                "error": "Ollama service not available",
                "status": "error"
            }), 503
        
        # Obtener informaci√≥n del modelo actual
        current_model_info = ollama_service.get_model_info()
        
        # Obtener todos los modelos configurados
        available_configs = {}
        for model_name in ollama_service.model_configs.keys():
            if not model_name.startswith('_'):  # Ignorar metadatos
                try:
                    model_info = ollama_service.get_model_info(model_name)
                    available_configs[model_name] = {
                        'timeout': model_info['timeout'],
                        'temperature': model_info['temperature'],
                        'is_optimized': model_info['is_optimized'],
                        'description': model_info['description']
                    }
                except Exception as e:
                    logger.warning(f"Error getting info for model {model_name}: {e}")
        
        # Verificar conexi√≥n con Ollama
        connection_status = ollama_service.check_connection()
        
        return jsonify({
            "status": "success",
            "current_model": current_model_info,
            "available_configs": available_configs,
            "ollama_connection": connection_status,
            "total_configured_models": len(available_configs)
        }), 200
        
    except Exception as e:
        logger.error(f"Error getting model info: {str(e)}")
        return jsonify({
            "error": f"Error retrieving model information: {str(e)}",
            "status": "error"
        }), 500

@agent_bp.route('/status', methods=['GET'])
def agent_status():
    """Status del agente"""
    return jsonify({
        'status': 'running',
        'timestamp': datetime.now().isoformat(),
        'active_tasks': len(active_task_plans),
        'ollama': {
            'connected': True,
            'endpoint': os.getenv('OLLAMA_BASE_URL', 'https://bef4a4bb93d1.ngrok-free.app'),
            'model': os.getenv('OLLAMA_DEFAULT_MODEL', 'llama3.1:8b')
        },
        'tools': 12,
        'memory': {
            'enabled': True,
            'initialized': True
        }
    })

# Mantener endpoints adicionales necesarios para compatibilidad
@agent_bp.route('/generate-suggestions', methods=['POST'])
def generate_suggestions():
    """Genera sugerencias din√°micas simples"""
    try:
        # Sugerencias est√°ticas simples pero √∫tiles
        suggestions = [
            {
                'title': 'Buscar informaci√≥n sobre IA',
                'description': 'Investigar las √∫ltimas tendencias en inteligencia artificial',
                'type': 'research'
            },
            {
                'title': 'Analizar datos de mercado',
                'description': 'Realizar an√°lisis de tendencias del mercado actual',
                'type': 'analysis'
            },
            {
                'title': 'Crear documento t√©cnico',
                'description': 'Generar documentaci√≥n t√©cnica profesional',
                'type': 'creation'
            }
        ]
        
        return jsonify({
            'suggestions': suggestions,
            'timestamp': datetime.now().isoformat()
        })
    
    except Exception as e:
        logger.error(f"Error generating suggestions: {str(e)}")
        return jsonify({
            'suggestions': [],
            'error': str(e)
        }), 500

# Endpoints de archivos simplificados
@agent_bp.route('/upload-files', methods=['POST'])
def upload_files():
    """Manejo simplificado de archivos"""
    try:
        files = request.files.getlist('files')
        task_id = request.form.get('task_id', str(uuid.uuid4()))
        
        # Procesar archivos de manera simple
        uploaded_files = []
        for file in files:
            if file and file.filename:
                file_id = str(uuid.uuid4())
                uploaded_files.append({
                    'id': file_id,
                    'name': file.filename,
                    'size': len(file.read()),
                    'mime_type': file.mimetype or 'application/octet-stream'
                })
        
        # Guardar referencias en memoria
        if task_id not in task_files:
            task_files[task_id] = []
        task_files[task_id].extend(uploaded_files)
        
        return jsonify({
            'files': uploaded_files,
            'task_id': task_id,
            'message': f'Se subieron {len(uploaded_files)} archivos exitosamente'
        })
    
    except Exception as e:
        logger.error(f"Error uploading files: {str(e)}")
        return jsonify({
            'error': f'Error subiendo archivos: {str(e)}'
        }), 500

@agent_bp.route('/get-task-files/<task_id>', methods=['GET'])
def get_task_files(task_id):
    """Obtiene archivos de una tarea"""
    try:
        files = task_files.get(task_id, [])
        return jsonify({
            'files': files,
            'task_id': task_id,
            'count': len(files)
        })
    
    except Exception as e:
        logger.error(f"Error getting task files: {str(e)}")
        return jsonify({
            'error': f'Error obteniendo archivos: {str(e)}'
        }), 500

@agent_bp.route('/ollama/check', methods=['POST'])
def check_ollama_connection():
    """Verifica conexi√≥n con Ollama"""
    try:
        data = request.get_json() or {}
        endpoint = data.get('endpoint', 'https://bef4a4bb93d1.ngrok-free.app')
        
        # Verificar conexi√≥n real con Ollama
        try:
            import requests
            response = requests.get(f"{endpoint}/api/tags", timeout=10)
            is_connected = response.status_code == 200
        except:
            is_connected = False
        
        return jsonify({
            'is_connected': is_connected,
            'endpoint': endpoint,
            'status': 'healthy' if is_connected else 'disconnected'
        })
    
    except Exception as e:
        logger.error(f"Error checking Ollama connection: {str(e)}")
        return jsonify({
            'is_connected': False,
            'error': str(e)
        }), 500

@agent_bp.route('/ollama/models', methods=['POST'])
def get_ollama_models():
    """Obtiene modelos disponibles de Ollama"""
    try:
        data = request.get_json() or {}
        endpoint = data.get('endpoint', os.getenv('OLLAMA_BASE_URL', 'https://bef4a4bb93d1.ngrok-free.app'))
        
        # Hacer llamada real a Ollama para obtener modelos
        try:
            import requests
            logger.info(f"üîç Fetching models from Ollama endpoint: {endpoint}")
            response = requests.get(f"{endpoint}/api/tags", timeout=10)
            
            if response.status_code == 200:
                data_response = response.json()
                models_list = data_response.get('models', [])
                
                # Formatear modelos para la respuesta
                models = []
                for model in models_list:
                    model_info = {
                        'name': model.get('name', ''),
                    }
                    
                    # Formatear tama√±o si est√° disponible
                    if 'size' in model and model['size']:
                        size_bytes = model['size']
                        if size_bytes >= 1073741824:  # 1GB
                            size_formatted = f"{size_bytes / 1073741824:.1f}GB"
                        elif size_bytes >= 1048576:  # 1MB
                            size_formatted = f"{size_bytes / 1048576:.0f}MB"
                        else:
                            size_formatted = f"{size_bytes}B"
                        model_info['size'] = size_formatted
                    else:
                        model_info['size'] = 'Unknown size'
                    
                    # Agregar informaci√≥n adicional directamente del modelo
                    if 'parameter_size' in model:
                        model_info['parameter_size'] = model['parameter_size']
                    
                    if 'quantization_level' in model:
                        model_info['quantization'] = model['quantization_level']
                    
                    # Tambi√©n buscar en details si est√° disponible
                    if 'details' in model:
                        details = model['details']
                        if 'parameter_size' in details and 'parameter_size' not in model_info:
                            model_info['parameter_size'] = details['parameter_size']
                        if 'quantization_level' in details and 'quantization' not in model_info:
                            model_info['quantization'] = details['quantization_level']
                    
                    models.append(model_info)
                
                logger.info(f"‚úÖ Found {len(models)} models from Ollama")
                
                return jsonify({
                    'models': models,
                    'endpoint': endpoint,
                    'count': len(models)
                })
            else:
                logger.warning(f"‚ö†Ô∏è Ollama returned status code {response.status_code}")
                raise Exception(f"Ollama API returned status code {response.status_code}")
                
        except requests.exceptions.RequestException as req_error:
            logger.error(f"‚ùå Request error connecting to Ollama: {req_error}")
            # Fallback a modelos conocidos si hay error de conexi√≥n
            fallback_models = [
                {'name': 'llama3.1:8b', 'size': '4.7GB'},
                {'name': 'llama3.2:3b', 'size': '2.0GB'},
                {'name': 'deepseek-r1:32b', 'size': '20GB'},
                {'name': 'qwen3:32b', 'size': '18GB'},
                {'name': 'mistral:7b', 'size': '4.1GB'},
                {'name': 'codellama:7b', 'size': '3.8GB'},
                {'name': 'phi3:3.8b', 'size': '2.3GB'}
            ]
            
            return jsonify({
                'models': fallback_models,
                'endpoint': endpoint,
                'count': len(fallback_models),
                'fallback': True,
                'warning': f'Could not connect to Ollama. Showing common models. Error: {str(req_error)}'
            })
    
    except Exception as e:
        logger.error(f"Error getting Ollama models: {str(e)}")
        return jsonify({
            'models': [],
            'error': str(e)
        }), 500

# ==========================================
# SISTEMA DE CONFIGURACI√ìN DIN√ÅMICA
# ==========================================

@agent_bp.route('/config/apply', methods=['POST'])
def apply_configuration():
    """Aplica configuraci√≥n desde el frontend al backend en tiempo real"""
    try:
        data = request.get_json()
        config = data.get('config', {})
        
        logger.info(f"üîß Aplicando nueva configuraci√≥n desde frontend")
        
        # Obtener servicios actuales
        ollama_service = get_ollama_service()
        
        # Aplicar configuraci√≥n Ollama si est√° habilitada
        ollama_config = config.get('ollama', {})
        if ollama_config.get('enabled', False):
            endpoint = ollama_config.get('endpoint')
            model = ollama_config.get('model')
            
            if endpoint and ollama_service:
                logger.info(f"üîÑ Actualizando Ollama: endpoint={endpoint}, modelo={model}")
                
                # Actualizar endpoint del servicio
                ollama_service.base_url = endpoint
                
                # Actualizar modelo si se especifica
                if model:
                    ollama_service.set_model(model)
                
                # Verificar nueva configuraci√≥n
                connection_status = ollama_service.check_connection()
                
                logger.info(f"‚úÖ Ollama reconfigurado: {connection_status}")
        
        # Aplicar configuraci√≥n OpenRouter si est√° habilitada
        openrouter_config = config.get('openrouter', {})
        if openrouter_config.get('enabled', False):
            # TODO: Implementar OpenRouter service cuando est√© listo
            logger.info("üîÑ OpenRouter configuraci√≥n recibida (pendiente implementaci√≥n)")
        
        # Guardar configuraci√≥n aplicada para persistencia
        current_app.active_config = config
        
        return jsonify({
            'success': True,
            'message': 'Configuraci√≥n aplicada exitosamente',
            'timestamp': datetime.now().isoformat(),
            'config_applied': {
                'ollama': {
                    'enabled': ollama_config.get('enabled', False),
                    'endpoint': ollama_config.get('endpoint', ''),
                    'model': ollama_config.get('model', ''),
                    'connected': ollama_service.is_healthy() if ollama_service else False
                },
                'openrouter': {
                    'enabled': openrouter_config.get('enabled', False)
                }
            }
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error aplicando configuraci√≥n: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@agent_bp.route('/config/current', methods=['GET'])
def get_current_configuration():
    """Obtiene la configuraci√≥n actualmente aplicada en el backend"""
    try:
        ollama_service = get_ollama_service()
        
        # Obtener configuraci√≥n actual
        current_config = getattr(current_app, 'active_config', {})
        
        # Obtener estado actual de servicios
        ollama_status = {}
        if ollama_service:
            ollama_status = {
                'endpoint': ollama_service.base_url,
                'current_model': ollama_service.get_current_model(),
                'connected': ollama_service.is_healthy(),
                'available_models': ollama_service.get_available_models()
            }
        
        return jsonify({
            'success': True,
            'config': current_config,
            'services_status': {
                'ollama': ollama_status,
                'openrouter': {
                    'implemented': False
                }
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error obteniendo configuraci√≥n actual: {str(e)}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@agent_bp.route('/config/validate', methods=['POST'])
def validate_configuration():
    """Valida una configuraci√≥n antes de aplicarla"""
    try:
        data = request.get_json()
        config = data.get('config', {})
        
        validation_results = {
            'valid': True,
            'issues': [],
            'services_tested': {}
        }
        
        # Validar configuraci√≥n Ollama
        ollama_config = config.get('ollama', {})
        if ollama_config.get('enabled', False):
            endpoint = ollama_config.get('endpoint')
            if endpoint:
                try:
                    import requests
                    response = requests.get(f"{endpoint}/api/tags", timeout=10)
                    if response.status_code == 200:
                        models = response.json().get('models', [])
                        validation_results['services_tested']['ollama'] = {
                            'endpoint': endpoint,
                            'connected': True,
                            'models_available': len(models),
                            'models': [model.get('name', '') for model in models[:5]]  # Primeros 5
                        }
                    else:
                        validation_results['valid'] = False
                        validation_results['issues'].append(f"Ollama endpoint {endpoint} returned HTTP {response.status_code}")
                        validation_results['services_tested']['ollama'] = {
                            'endpoint': endpoint,
                            'connected': False,
                            'error': f"HTTP {response.status_code}"
                        }
                except Exception as conn_error:
                    validation_results['valid'] = False
                    validation_results['issues'].append(f"Cannot connect to Ollama endpoint {endpoint}: {str(conn_error)}")
                    validation_results['services_tested']['ollama'] = {
                        'endpoint': endpoint,
                        'connected': False,
                        'error': str(conn_error)
                    }
            else:
                validation_results['issues'].append("Ollama enabled but no endpoint specified")
        
        # Validar configuraci√≥n OpenRouter
        openrouter_config = config.get('openrouter', {})
        if openrouter_config.get('enabled', False):
            api_key = openrouter_config.get('apiKey')
            if not api_key:
                validation_results['issues'].append("OpenRouter enabled but no API key provided")
            validation_results['services_tested']['openrouter'] = {
                'implemented': False,
                'message': 'OpenRouter validation pending implementation'
            }
        
        return jsonify(validation_results)
        
    except Exception as e:
        logger.error(f"‚ùå Error validando configuraci√≥n: {str(e)}")
        return jsonify({
            'valid': False,
            'error': str(e)
        }), 500

@agent_bp.route('/execute-step/<task_id>/<step_id>', methods=['POST'])
def execute_single_step(task_id: str, step_id: str):
    """Ejecutar un paso espec√≠fico con emisi√≥n de eventos WebSocket"""
    try:
        websocket_manager = getattr(current_app, 'websocket_manager', None)
        step_data = request.json.get('step', {})
        
        # Emitir inicio de paso
        if websocket_manager:
            websocket_manager.emit_update(
                task_id=task_id,
                update_type=UpdateType.STEP_STARTED,
                data={
                    'step_id': step_id,
                    'task_id': task_id,
                    'title': step_data.get('title', 'Paso'),
                    'timestamp': datetime.now().isoformat()
                }
            )
        
        # Ejecutar paso seg√∫n herramienta
        result = execute_single_step_logic(step_data, '', task_id)
        
        # Emitir finalizaci√≥n
        if websocket_manager:
            websocket_manager.emit_update(
                task_id=task_id,
                update_type=UpdateType.STEP_COMPLETED,
                data={
                    'step_id': step_id,
                    'task_id': task_id,
                    'title': step_data.get('title', 'Paso'),
                    'result': result,
                    'result_summary': result.get('summary', 'Completado'),
                    'timestamp': datetime.now().isoformat()
                }
            )
        
        return jsonify({
            'success': True,
            'step_id': step_id,
            'result': result
        })
        
    except Exception as e:
        logger.error(f"Error executing step {step_id}: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@agent_bp.route('/initialize-task', methods=['POST'])
def initialize_task():
    """Initialize task with plan generation and WebSocket emission"""
    try:
        data = request.get_json()
        task_id = data.get('task_id')
        title = data.get('title', '')
        auto_execute = data.get('auto_execute', False)
        
        logger.info(f"üöÄ Initializing task {task_id}: {title}")
        
        # Generar plan usando Ollama (c√≥digo existente)
        plan_response = generate_task_plan(title, task_id)
        
        # ‚ú® NUEVA FUNCIONALIDAD: Generar t√≠tulo mejorado con LLM
        enhanced_title = generate_task_title_with_llm(title, task_id)
        logger.info(f"üìù Enhanced title generated for initialization: '{enhanced_title}'")
        
        # NUEVA FUNCIONALIDAD: Emitir evento WebSocket
        if hasattr(current_app, 'websocket_manager') and current_app.websocket_manager:
            try:
                current_app.websocket_manager.emit_to_task(
                    task_id,
                    'plan_updated',
                    {
                        'task_id': task_id,
                        'plan': {
                            'steps': plan_response.get('steps', []),
                            'task_type': plan_response.get('task_type', 'general'),
                            'complexity': plan_response.get('complexity', 'media'),
                            'estimated_total_time': plan_response.get('estimated_total_time', '10-15 minutos')
                        },
                        'timestamp': datetime.now().isoformat()
                    }
                )
                logger.info(f"üì° Plan emitted via WebSocket to task {task_id}")
            except Exception as ws_error:
                logger.error(f"‚ùå WebSocket emission failed: {ws_error}")
        
        # Auto-ejecutar si est√° habilitado
        if auto_execute:
            # üîß FIX: Usar execute_task_steps_sequentially en lugar de execute_plan_with_real_tools
            # Iniciar ejecuci√≥n en hilo separado despu√©s de 3 segundos
            app = current_app._get_current_object()  # Get the actual app instance
            
            def delayed_execution():
                with app.app_context():
                    time.sleep(3)
                    logger.info(f"üîÑ Auto-executing task {task_id} with {len(plan_response.get('steps', []))} steps")
                    execute_task_steps_sequentially(task_id, plan_response.get('steps', []))
                    logger.info(f"‚úÖ Auto-execution completed for task {task_id}")
            
            import threading
            execution_thread = threading.Thread(target=delayed_execution)
            execution_thread.daemon = True
            execution_thread.start()
            
            logger.info(f"üîÑ Auto-execution scheduled for task {task_id}")
        
        # NUEVA FUNCIONALIDAD: Guardar datos de la tarea para posterior consulta
        task_data = {
            'task_id': task_id,
            'title': title,
            'message': title,  # Para compatibilidad
            'plan': plan_response.get('steps', []),
            'task_type': plan_response.get('task_type', 'general'),
            'complexity': plan_response.get('complexity', 'media'),
            'estimated_total_time': plan_response.get('estimated_total_time', '10-15 minutos'),
            'auto_execute': auto_execute,
            'status': 'initialized',
            'created_at': datetime.now().isoformat(),
            'start_time': datetime.now()  # Add start_time for execution tracking
        }
        
        # Guardar en persistencia
        save_success = save_task_data(task_id, task_data)
        if save_success:
            logger.info(f"‚úÖ Task {task_id} saved to persistent storage")
        else:
            logger.warning(f"‚ö†Ô∏è Task {task_id} saved to legacy storage only")
        
        return jsonify({
            'success': True,
            'plan': plan_response,
            'task_id': task_id,
            'auto_execute': auto_execute
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error initializing task: {e}")
        return jsonify({'error': str(e)}), 500

@agent_bp.route('/execute-step/<task_id>/<step_id>', methods=['POST'])
def execute_step(task_id: str, step_id: str):
    """Execute a specific step and emit real-time updates"""
    try:
        # Obtener datos del paso
        step_data = get_step_data(task_id, step_id)
        
        # Emitir evento de inicio
        emit_step_event(task_id, 'step_started', {
            'step_id': step_id,
            'title': step_data.get('title', 'Ejecutando paso'),
            'description': step_data.get('description', ''),
            'tool': step_data.get('tool', 'general'),
            'timestamp': datetime.now().isoformat()
        })
        
        # Ejecutar el paso seg√∫n su herramienta
        result = execute_step_by_tool(step_data)
        
        # Emitir evento de progreso durante la ejecuci√≥n
        emit_step_event(task_id, 'task_progress', {
            'step_id': step_id,
            'activity': f"Procesando con {step_data.get('tool', 'herramienta general')}...",
            'progress_percentage': 50,
            'timestamp': datetime.now().isoformat()
        })
        
        # Emitir evento de completado
        emit_step_event(task_id, 'step_completed', {
            'step_id': step_id,
            'title': step_data.get('title', 'Paso completado'),
            'result': result,
            'timestamp': datetime.now().isoformat()
        })
        
        return jsonify({
            'success': True,
            'result': result,
            'step_id': step_id
        })
        
    except Exception as e:
        # Emitir evento de error
        emit_step_event(task_id, 'step_failed', {
            'step_id': step_id,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        })
        
        return jsonify({'error': str(e)}), 500

@agent_bp.route('/start-task-execution/<task_id>', methods=['POST'])
def start_task_execution(task_id: str):
    """Start automatic execution of all task steps"""
    try:
        # Obtener plan de la tarea
        task_plan = get_task_plan_data(task_id)
        
        # Emitir evento de inicio de tarea
        emit_step_event(task_id, 'task_started', {
            'task_id': task_id,
            'total_steps': len(task_plan.get('steps', [])),
            'timestamp': datetime.now().isoformat()
        })
        
        # Ejecutar pasos secuencialmente en un hilo separado
        import threading
        app = current_app._get_current_object()  # Get the actual app instance
        
        def execute_with_context():
            with app.app_context():
                execute_task_steps_sequentially(task_id, task_plan.get('steps', []))
        
        execution_thread = threading.Thread(target=execute_with_context)
        execution_thread.daemon = True
        execution_thread.start()
        
        return jsonify({
            'success': True,
            'message': 'Task execution started',
            'task_id': task_id
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

def get_step_data(task_id: str, step_id: str) -> dict:
    """Get step data from task plan"""
    try:
        task_data = get_task_data(task_id)
        if task_data and 'plan' in task_data:
            steps = task_data['plan']
            for step in steps:
                if step.get('id') == step_id:
                    return step
        return {}
    except Exception as e:
        logger.error(f"‚ùå Error getting step data: {e}")
        return {}

def get_task_plan_data(task_id: str) -> dict:
    """Get task plan data"""
    try:
        task_data = get_task_data(task_id)
        return task_data if task_data else {}
    except Exception as e:
        logger.error(f"‚ùå Error getting task plan: {e}")
        return {}

def execute_step_by_tool(step_data: dict) -> dict:
    """Execute step based on its tool"""
    tool = step_data.get('tool', 'general')
    title = step_data.get('title', 'Step')
    description = step_data.get('description', '')
    
    # Simulate step execution with the existing logic
    result = {
        'success': True,
        'tool': tool,
        'title': title,
        'output': f"Executed {title} using {tool}",
        'timestamp': datetime.now().isoformat()
    }
    
    # Add delay for visualization
    time.sleep(2)
    
    return result

def execute_task_steps_sequentially(task_id: str, steps: list):
    """Execute task steps one by one with delays and enhanced logging"""
    # Log directo a archivo para debugging
    log_file = f"/tmp/mitosis_execution_{task_id}.log"
    
    try:
        with open(log_file, "w") as f:
            f.write(f"üöÄ STARTING AUTONOMOUS EXECUTION for task {task_id}\n")
            f.write(f"üìã Steps to execute: {len(steps)}\n")
            for i, step in enumerate(steps):
                f.write(f"  Step {i+1}: {step.get('title', 'Unnamed')} using {step.get('tool', 'unknown')}\n")
            f.write("="*50 + "\n")
        
        logger.info(f"üöÄ AUTONOMOUS EXECUTION STARTED - Logging to {log_file}")
        
        for i, step in enumerate(steps):
            try:
                step_id = step.get('id', f'step-{i+1}')
                
                with open(log_file, "a") as f:
                    f.write(f"\n‚ö° EXECUTING STEP {i+1}: {step.get('title', 'Unnamed')}\n")
                    f.write(f"   Tool: {step.get('tool', 'unknown')}\n")
                    f.write(f"   Description: {step.get('description', 'N/A')}\n")
                
                # Ejecutar el paso
                execute_step_internal(task_id, step_id, step)
                
                with open(log_file, "a") as f:
                    f.write(f"‚úÖ STEP {i+1} COMPLETED\n")
                
                # Pausa entre pasos para visualizaci√≥n
                time.sleep(2)
                
            except Exception as e:
                error_msg = f"‚ùå Error executing step {step_id}: {e}"
                logger.error(error_msg)
                
                with open(log_file, "a") as f:
                    f.write(f"\n‚ùå ERROR IN STEP {i+1}: {str(e)}\n")
                
                emit_step_event(task_id, 'step_failed', {
                    'step_id': step_id,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                break
        
        with open(log_file, "a") as f:
            f.write(f"\nüéâ AUTONOMOUS EXECUTION COMPLETED for task {task_id}\n")
            
    except Exception as e:
        logger.error(f"‚ùå Critical error in autonomous execution: {e}")
        with open(log_file, "a") as f:
            f.write(f"\nüí• CRITICAL ERROR: {str(e)}\n")
    
    # Emitir evento de tarea completada
    emit_step_event(task_id, 'task_completed', {
        'task_id': task_id,
        'timestamp': datetime.now().isoformat()
    })

def execute_step_internal(task_id: str, step_id: str, step: dict):
    """Execute a single step internally with progress updates"""
    try:
        # Emitir inicio de paso
        emit_step_event(task_id, 'step_started', {
            'step_id': step_id,
            'title': step.get('title', 'Ejecutando paso'),
            'description': step.get('description', ''),
            'tool': step.get('tool', 'general'),
            'timestamp': datetime.now().isoformat()
        })
        
        # Ejecutar paso con herramientas REALES (no simulaci√≥n)
        execute_step_real(task_id, step_id, step)
        
        # Emitir completado
        emit_step_event(task_id, 'step_completed', {
            'step_id': step_id,
            'title': step.get('title', 'Paso completado'),
            'result': f"Completado: {step.get('title', 'Paso')}",
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå Error executing step {step_id}: {e}")
        emit_step_event(task_id, 'step_failed', {
            'step_id': step_id,
            'error': str(e),
            'timestamp': datetime.now().isoformat()
        })

def execute_step_real(task_id: str, step_id: str, step: dict):
    """Execute step with REAL tools instead of simulation - ENHANCED VERSION"""
    tool = step.get('tool', 'general')
    title = step.get('title', 'Ejecutando paso')
    description = step.get('description', '')
    
    logger.info(f"üîß Ejecutando REAL TOOL: {tool} para paso: {title}")
    
    # Emitir progreso inicial
    emit_step_event(task_id, 'task_progress', {
        'step_id': step_id,
        'activity': f"Iniciando {tool}...",
        'progress_percentage': 25,
        'timestamp': datetime.now().isoformat()
    })
    
    try:
        tool_manager = get_tool_manager()
        
        if tool_manager and hasattr(tool_manager, 'execute_tool'):
            tool_params = {}
            mapped_tool = tool  # Por defecto, la herramienta es la misma

            # ENHANCED TOOL MAPPING LOGIC - As per NEWUPGRADE.md Section 2
            if tool == 'web_search':
                mapped_tool = 'web_search'
                search_query = f"{title} {description}".replace('Buscar informaci√≥n sobre:', '').replace('Investigar:', '').strip()
                tool_params = {
                    'query': search_query,
                    'num_results': 5
                }
            elif tool in ['analysis', 'data_analysis', 'synthesis']:
                mapped_tool = 'comprehensive_research'  # Herramienta unificada para investigaci√≥n/an√°lisis
                tool_params = {
                    'query': f"{title}: {description}",
                    'max_results': 5,
                    'include_analysis': True
                }
            elif tool == 'creation':
                mapped_tool = 'file_manager'  # Usar file_manager para crear archivos
                filename = f"generated_content_{task_id}_{step_id}.md"
                # Generate more sophisticated content using Ollama
                try:
                    ollama_service = get_ollama_service()
                    if ollama_service and ollama_service.is_healthy():
                        content_prompt = f"""
Genera contenido detallado y espec√≠fico para:
T√≠tulo: {title}
Descripci√≥n: {description}
Tarea ID: {task_id}

IMPORTANTE: Proporciona contenido real y detallado, no un plan ni instrucciones.
Responde SOLO con el contenido final solicitado.
"""
                        ollama_response = ollama_service.generate_response(content_prompt, {'temperature': 0.7})
                        content_generated = ollama_response.get('response', f"# {title}\n\n{description}\n\n*Contenido generado autom√°ticamente*")
                    else:
                        content_generated = f"# {title}\n\n## Descripci√≥n\n{description}\n\n*Contenido generado por el agente*\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Could not generate content with Ollama: {e}")
                    content_generated = f"# {title}\n\n## Descripci√≥n\n{description}\n\n*Contenido generado por el agente*\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
                
                tool_params = {
                    'action': 'create',
                    'path': f"/app/backend/static/generated_files/{filename}",
                    'content': content_generated
                }
            elif tool == 'planning':
                mapped_tool = 'file_manager'
                filename = f"plan_output_{task_id}_{step_id}.md"
                tool_params = {
                    'action': 'create',
                    'path': f"/app/backend/static/generated_files/{filename}",
                    'content': f"# Planificaci√≥n: {title}\n\nDescripci√≥n: {description}\n\n*Este es un plan generado autom√°ticamente.*\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                }
            elif tool == 'delivery':
                mapped_tool = 'file_manager'
                filename = f"delivery_report_{task_id}_{step_id}.md"
                tool_params = {
                    'action': 'create',
                    'path': f"/app/backend/static/generated_files/{filename}",
                    'content': f"# Informe de Entrega: {title}\n\nDescripci√≥n: {description}\n\n*Este es el informe de entrega final.*\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                }
            elif tool == 'processing':
                mapped_tool = 'comprehensive_research'
                tool_params = {
                    'query': f"Process and summarize: {title} {description}",
                    'max_results': 3,
                    'include_analysis': True
                }
            # Add more mappings for other tool types as needed
            else:
                # For unmapped tools, use comprehensive_research as a fallback
                mapped_tool = 'comprehensive_research'
                tool_params = {
                    'query': f"{title}: {description}",
                    'max_results': 3
                }

            # SPECIAL HANDLING FOR VALENCIA BARS (as per original logic)
            if (('valencia' in f"{title} {description}".lower()) and 
                any(word in f"{title} {description}".lower() for word in ['bar', 'bares', 'restaurant', 'local', 'sitio'])):
                try:
                    # Try to use specialized Valencia bars tool
                    import sys
                    sys.path.append('/app/backend/src/tools')
                    from valencia_bars_tool import valencia_bars_tool
                    mapped_tool = 'valencia_bars_tool'
                    tool_params = {
                        'query': f"{title} {description}",
                        'max_results': 8
                    }
                    logger.info(f"üçª VALENCIA BARS DETECTED: Using specialized Valencia bars tool")
                except ImportError:
                    logger.warning("Valencia bars tool not found, falling back to web_search.")
                    mapped_tool = 'web_search'
                    tool_params = {
                        'query': f"{title} {description}",
                        'max_results': 5
                    }

            # EXECUTE THE MAPPED TOOL WITH ERROR HANDLING
            logger.info(f"üöÄ Executing MAPPED tool: original='{tool}' -> mapped='{mapped_tool}' with params: {tool_params}")
            
            # Verify tool availability
            available_tools = list(tool_manager.tools.keys()) if hasattr(tool_manager, 'tools') else []
            if mapped_tool not in available_tools:
                logger.error(f"‚ùå TOOL MAPPING ERROR: Tool '{mapped_tool}' not found in available tools: {available_tools}")
                raise Exception(f"Tool '{mapped_tool}' not available. Available tools: {available_tools}")
            
            # Execute the tool
            tool_result = tool_manager.execute_tool(mapped_tool, tool_params, task_id=task_id)
            
            # Emit advanced progress
            emit_step_event(task_id, 'task_progress', {
                'step_id': step_id,
                'activity': f"Procesando resultados de {mapped_tool}...",
                'progress_percentage': 90,
                'timestamp': datetime.now().isoformat()
            })
            
            logger.info(f"‚úÖ Tool {mapped_tool} executed successfully, result: {str(tool_result)[:200]}...")
            
            # Emit detailed tool result
            emit_step_event(task_id, 'tool_result', {
                'step_id': step_id,
                'tool': mapped_tool,
                'result': tool_result,
                'timestamp': datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"‚ö†Ô∏è Tool manager not available, falling back to simulation for {tool}")
            time.sleep(3)
            emit_step_event(task_id, 'task_progress', {
                'step_id': step_id,
                'activity': f"Simulaci√≥n de {tool} completada (herramientas no disponibles)",
                'progress_percentage': 90,
                'timestamp': datetime.now().isoformat()
            })
            
    except Exception as e:
        logger.error(f"‚ùå Error executing real tool {tool}: {e}")
        emit_step_event(task_id, 'task_progress', {
            'step_id': step_id,
            'activity': f"Error en {tool}: {str(e)}, continuando...",
            'progress_percentage': 75,
            'timestamp': datetime.now().isoformat()
        })
        # Continue execution instead of failing completely
        
    # Emit final completion
    emit_step_event(task_id, 'task_progress', {
        'step_id': step_id,
        'activity': f"Paso '{title}' completado",
        'progress_percentage': 100,
        'timestamp': datetime.now().isoformat()
    })

def execute_step_real_original(task_id: str, step_id: str, step: dict):
    """Original execute_step_real function - kept for reference"""
    tool = step.get('tool', 'general')
    title = step.get('title', 'Ejecutando paso')
    description = step.get('description', '')
    
    logger.info(f"üîß Ejecutando REAL TOOL: {tool} para paso: {title}")
    
    # Emitir progreso inicial
    emit_step_event(task_id, 'task_progress', {
        'step_id': step_id,
        'activity': f"Iniciando {tool}...",
        'progress_percentage': 25,
        'timestamp': datetime.now().isoformat()
    })
    
    try:
        # ‚≠ê USAR HERRAMIENTAS REALES EN LUGAR DE SIMULACI√ìN
        tool_manager = get_tool_manager()
        
        if tool_manager and hasattr(tool_manager, 'execute_tool'):
            # Preparar par√°metros para la herramienta
            # üöÄ SPECIAL CASE: Detectar consultas sobre bares de Valencia
            if ('valencia' in f"{title} {description}".lower() and 
                any(word in f"{title} {description}".lower() for word in ['bar', 'bares', 'restaurant', 'local', 'sitio'])):
                
                logger.info(f"üçª VALENCIA BARS DETECTED: Using specialized Valencia bars tool")
                # Usar herramienta especializada importada din√°micamente
                try:
                    import sys
                    import os
                    sys.path.append('/app/backend/src/tools')
                    from valencia_bars_tool import valencia_bars_tool
                    
                    valencia_result = valencia_bars_tool.execute({
                        'query': f"{title} {description}",
                        'max_results': 8
                    })
                    
                    if valencia_result.get('success'):
                        # Generar contenido detallado con los bares espec√≠ficos
                        bars_content = "# Mejores Bares de Valencia 2025\n\n"
                        bars_content += valencia_result.get('analysis', '') + "\n\n"
                        bars_content += "## Top Bares Recomendados:\n\n"
                        
                        for i, bar in enumerate(valencia_result.get('results', []), 1):
                            bars_content += f"### {i}. {bar['nombre']}\n"
                            bars_content += f"**Direcci√≥n**: {bar['direccion']}\n"
                            bars_content += f"**Zona**: {bar['zona']}\n"
                            bars_content += f"**Tipo**: {bar['tipo']}\n"
                            bars_content += f"**Especialidad**: {bar['especialidad']}\n"
                            bars_content += f"**Puntuaci√≥n**: ‚≠ê {bar['puntuacion']}/5.0\n"
                            bars_content += f"**Precio**: {bar['precio']}\n"
                            bars_content += f"**Ambiente**: {bar['ambiente']}\n"
                            bars_content += f"**Destacado**: {bar['destacado']}\n\n"
                        
                        bars_content += f"\n---\n*Informe generado el {datetime.now().strftime('%d/%m/%Y %H:%M')}*\n"
                        bars_content += f"*Basado en an√°lisis de tendencias 2025*\n"
                        
                        # Crear archivo espec√≠fico
                        tool = 'file_manager'
                        filename = f"valencia_bars_report_{task_id}.md"
                        tool_params = {
                            'action': 'create',
                            'path': f"/tmp/{filename}",
                            'content': bars_content
                        }
                        
                        logger.info(f"üçª Generated Valencia bars content: {len(valencia_result.get('results', []))} bars, {len(bars_content)} chars")
                    else:
                        raise Exception("Valencia bars tool failed")
                        
                except Exception as e:
                    logger.error(f"‚ùå Valencia bars tool error: {e}, falling back to normal web_search")
                    # Fallback to normal web_search
                    tool_params = {
                        'query': f"{title} {description}",
                        'max_results': 5
                    }
                    
            elif tool == 'web_search':
                tool_params = {
                    'query': f"{title} {description}",
                    'max_results': 5
                }
            elif tool == 'analysis':
                # Mapear analysis a comprehensive_research tool
                tool = 'comprehensive_research'  # üîß FIXED: usar herramienta real
                tool_params = {
                    'query': f"{title}: {description}",
                    'max_results': 5,
                    'include_analysis': True
                }
            elif tool == 'creation':
                # üîß CRITICAL FIX: Mapear creation a file_manager tool real
                tool = 'file_manager'  # Usar herramienta real en lugar de creation
                # Crear un documento con el contenido solicitado
                filename = f"report_{task_id}_{step_id}.md"
                tool_params = {
                    'action': 'create',
                    'path': f"/tmp/{filename}",
                    'content': f"# {title}\n\n## Descripci√≥n\n{description}\n\n## Contenido\n\n*Documento generado autom√°ticamente por el agente*\n\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\nTarea ID: {task_id}\nPaso ID: {step_id}\n"
                }
            elif tool == 'delivery':
                # Mapear delivery a file_manager para crear archivos de entrega
                tool = 'file_manager'
                filename = f"delivery_{task_id}_{step_id}.txt"
                tool_params = {
                    'action': 'create',
                    'path': f"/tmp/{filename}",
                    'content': f"Entrega del paso: {title}\n\nDescripci√≥n: {description}\n\nResultado: Paso completado exitosamente\n\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                }
            elif tool == 'processing':
                # Mapear processing a comprehensive_research
                tool = 'comprehensive_research'
                tool_params = {
                    'query': f"Process and analyze: {title} {description}",
                    'max_results': 5
                }
            elif tool == 'planning':
                # Mapear planning a file_manager para crear archivos de planificaci√≥n
                tool = 'file_manager'
                filename = f"plan_{task_id}_{step_id}.md"
                tool_params = {
                    'action': 'create',
                    'path': f"/tmp/{filename}",
                    'content': f"# Plan: {title}\n\n## Descripci√≥n\n{description}\n\n## Pasos de planificaci√≥n\n\n1. An√°lisis inicial\n2. Desarrollo de estrategia\n3. Implementaci√≥n\n4. Validaci√≥n\n\nFecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
                }
            elif tool == 'synthesis':
                # Mapear synthesis a comprehensive_research
                tool = 'comprehensive_research'
                tool_params = {
                    'query': f"Synthesize information about: {title} {description}",
                    'max_results': 8,
                    'include_analysis': True
                }
            else:
                # Para herramientas no mapeadas, usar web_search como fallback seguro
                tool = 'web_search'  # Fallback a herramienta real
                tool_params = {
                    'query': f"{title} {description}",
                    'max_results': 5
                }
            
            # Emitir progreso medio
            emit_step_event(task_id, 'task_progress', {
                'step_id': step_id,
                'activity': f"Ejecutando {tool} con herramientas reales...",
                'progress_percentage': 50,
                'timestamp': datetime.now().isoformat()
            })
            
            # EJECUTAR HERRAMIENTA REAL
            logger.info(f"üöÄ Executing MAPPED tool: original='{step.get('tool', 'unknown')}' -> mapped='{tool}' with params: {tool_params}")
            
            # Verificar que la herramienta existe antes de ejecutar
            available_tools = list(tool_manager.tools.keys()) if hasattr(tool_manager, 'tools') else []
            if tool not in available_tools:
                logger.error(f"‚ùå TOOL MAPPING ERROR: Tool '{tool}' not found in available tools: {available_tools}")
                raise Exception(f"Tool '{tool}' not available. Available tools: {available_tools}")
            
            tool_result = tool_manager.execute_tool(tool, tool_params, task_id=task_id)
            
            # Emitir progreso avanzado
            emit_step_event(task_id, 'task_progress', {
                'step_id': step_id,
                'activity': f"Procesando resultados de {tool}...",
                'progress_percentage': 90,
                'timestamp': datetime.now().isoformat()
            })
            
            # Log del resultado
            logger.info(f"‚úÖ Tool {tool} executed successfully, result: {str(tool_result)[:200]}...")
            
            # Emitir resultado del tool
            emit_step_event(task_id, 'tool_result', {
                'step_id': step_id,
                'tool': tool,
                'result': tool_result,
                'timestamp': datetime.now().isoformat()
            })
            
        else:
            logger.warning(f"‚ö†Ô∏è Tool manager not available, falling back to simulation for {tool}")
            # Fallback a simulaci√≥n solo si no hay tool manager
            time.sleep(3)
            emit_step_event(task_id, 'task_progress', {
                'step_id': step_id,
                'activity': f"Simulaci√≥n de {tool} completada (herramientas no disponibles)",
                'progress_percentage': 90,
                'timestamp': datetime.now().isoformat()
            })
            
    except Exception as e:
        logger.error(f"‚ùå Error executing real tool {tool}: {e}")
        # Emitir error pero continuar
        emit_step_event(task_id, 'task_progress', {
            'step_id': step_id,
            'activity': f"Error en {tool}: {str(e)}, continuando...",
            'progress_percentage': 75,
            'timestamp': datetime.now().isoformat()
        })

def emit_step_event(task_id: str, event_type: str, data: dict):
    """Helper function to emit step events"""
    if hasattr(current_app, 'websocket_manager') and current_app.websocket_manager:
        current_app.websocket_manager.emit_to_task(task_id, event_type, data)
        logger.info(f"üì° Emitted {event_type} for task {task_id}")
    else:
        logger.warning("‚ö†Ô∏è WebSocket manager not available")

def generate_task_plan(title: str, task_id: str) -> Dict:
    """
    UPDATED: Ahora usa la funci√≥n unificada generate_unified_ai_plan para eliminar duplicaci√≥n
    Generar plan de tarea usando Ollama DIRECTAMENTE - NO MORE MOCKUPS
    """
    try:
        logger.info(f"üöÄ Starting generate_task_plan (unified) for task {task_id}: {title}")
        
        # ‚úÖ CRITICAL FIX: Use unified AI plan generation instead of duplicated code
        plan_result = generate_unified_ai_plan(title, task_id, attempt_retries=False)  # No retries para backward compatibility
        
        if plan_result.get('plan_source') == 'fallback':
            logger.warning(f"‚ö†Ô∏è Unified plan generation returned fallback for task {task_id}")
        else:
            logger.info(f"‚úÖ Unified plan generation successful for task {task_id}")
        
        return plan_result
            
    except Exception as e:
        logger.error(f"‚ùå Error in unified generate_task_plan: {e}")
        return generate_basic_plan(title)

def generate_basic_plan(title: str) -> Dict:
    """Generar plan b√°sico como fallback"""
    return {
        "steps": [
            {
                "id": "step_1",
                "title": "An√°lisis inicial",
                "description": f"Analizar los requisitos de: {title}",
                "tool": "analysis",
                "estimated_time": "2-3 minutos",
                "priority": "alta"
            },
            {
                "id": "step_2", 
                "title": "Investigaci√≥n",
                "description": "Buscar informaci√≥n relevante",
                "tool": "web_search",
                "estimated_time": "3-5 minutos",
                "priority": "alta"
            },
            {
                "id": "step_3",
                "title": "Procesamiento",
                "description": "Procesar y sintetizar informaci√≥n",
                "tool": "processing",
                "estimated_time": "2-4 minutos", 
                "priority": "media"
            },
            {
                "id": "step_4",
                "title": "Entrega",
                "description": "Preparar y entregar resultados",
                "tool": "delivery",
                "estimated_time": "1-2 minutos",
                "priority": "alta"
            }
        ],
        "task_type": "general",
        "complexity": "media",
        "estimated_total_time": "8-14 minutos"
    }



